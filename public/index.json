[{"content":"Introduction Hello, world! I\u0026rsquo;m here again :D\n","permalink":"http://localhost:1313/games/second/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eHello, world! I\u0026rsquo;m here again :D\u003c/p\u003e","title":"Second"},{"content":"In the previous post, we generated images with circles and squares in Python with the package Pillow. The code was simple and the results are not that compelling. So, in this post I\u0026rsquo;m looking to step it up a bit. A while back Numberphile posted a video of Matt Henderson explaining how maze generation and breadth-first search can be used to generate a compelling animation of lightning. We are going to use a similar approach to generate images of lightning.\nWe\u0026rsquo;re taking a different approach from Henderson\u0026rsquo;s to generate lightning, but I have a few suggestions if you want to recreate Henderson\u0026rsquo;s work. For those interested in maze generation, Wikipedia has a stellar article that is an excellent starting point. Breadth-first search also has a very good Wikipedia article, but I would recommend looking at the post from the blog Red Blob Games, which has code and excellent animations with an interactive demo.\nWhen I started considering how to approach generating a lightning-like image, I initially was going to implement maze generation (probably with Kruskal\u0026rsquo;s algorithm) and a breadth-first search, but it seemed like a lot of work for a blog no one reads. So, how can I do the same thing with less work? Well, the maze and the search are not actually required. They make a beautiful animation, but you can get around it if you\u0026rsquo;re only generating the final image.\nThe idea of the approach is essentially a depth-first search where we randomly choose directions (down, left, right). However, if we are currently moving to the left then we cannot move to the right. Only once we have gone down at least once can we move again to the right. And that\u0026rsquo;s it. Add some bounds checking and you get the images above. The code to generate these images is below.\nfrom random import randrange, seed, randint, random, choice from PIL import Image, ImageDraw, ImageFont PIXEL_SIZE = 2 TOTAL_RUNS = 50 font = ImageFont.truetype(\u0026#34;ProzaLibre-Medium.ttf\u0026#34;, size=16) def draw_lightning(run_id): image = Image.new(\u0026#39;RGB\u0026#39;, (720, 480)) draw_image = ImageDraw.Draw(image) width, height = image.size x = randrange(100, width-100) y = 0 LEFT = (-PIXEL_SIZE, 0) RIGHT = (PIXEL_SIZE, 0) DOWN = (0, PIXEL_SIZE) turned_right = False turned_left = False fill=( randint(0, 255), randint(0, 255), randint(0, 255), 255 ) draw_image.rectangle( [(x, y),(x + PIXEL_SIZE, y + PIXEL_SIZE)], fill) while y \u0026lt; height: if turned_left: direction = choice([LEFT, DOWN]) if direction != LEFT: turned_left = False elif turned_right: direction = choice([RIGHT, DOWN]) if direction != RIGHT: turned_right = False else: direction = choice([LEFT, RIGHT, DOWN]) if direction == LEFT: turned_left = True elif direction == RIGHT: turned_right = True x += direction[0] y += direction[1] if x \u0026lt; 20: x = 20 elif x \u0026gt; width - 20: x = width - 20 else: draw_image.rectangle( [(x, y),(x + PIXEL_SIZE, y + PIXEL_SIZE)], fill) draw_image.text((width-200,height-32), f\u0026#39;bi3mer :: 0003 :: {run_id + 1}/{TOTAL_RUNS}\u0026#39;, (255,255,255), align=\u0026#39;right\u0026#39;, font=font) image.save(f\u0026#39;./output/0002_{run_id}.png\u0026#39;) for run_id in range(TOTAL_RUNS): seed(run_id) print(f\u0026#39;Processing run_id: {run_id}\u0026#39;) draw_lightning(run_id) Thanks for reading (if you did), and I hope you enjoyed the post.\n","permalink":"http://localhost:1313/posts/generative-art-lightning/","summary":"\u003cp\u003eIn the \u003ca href=\"../generative-art-circles-and-squares\"\u003eprevious post\u003c/a\u003e, we generated images with circles and squares in Python with the package \u003ca href=\"https://pillow.readthedocs.io/en/stable/\"\u003ePillow\u003c/a\u003e. The code was simple and the results are not that compelling. So, in this post I\u0026rsquo;m looking to step it up a bit. A while back \u003ca href=\"https://www.youtube.com/watch?v=akZ8JJ4gGLs\"\u003eNumberphile\u003c/a\u003e posted a video of \u003ca href=\"https://x.com/matthen2\"\u003eMatt Henderson\u003c/a\u003e explaining how maze generation and breadth-first search can be used to generate a compelling animation of lightning. We are going to use a similar approach to generate images of lightning.\u003c/p\u003e","title":"Generative Art Lightning"},{"content":"This is the first of what we\u0026rsquo;ll likely be a series of blog posts on generative art, specifically images. At the start, everything will be very simple. This is mainly because the topic is new to me and the library we\u0026rsquo;re going to use to generate images is also new to me. Speaking of, we\u0026rsquo;re going to be using Python and Pillow to generate images; at least at the start, we\u0026rsquo;ll see where we go. To start, I want to break this post into two parts: (1) pseudo-random and (2) generating a simple image with circles and squares.\nPseudo-Random Pseudo-random refers to the reality that nothing is ever truly random when it comes to computation. This is because we need to write code to generate the randomness which is inherently not random. The way we get around this is through functions that appear random to us but are pseudo-random because they output the same value every time for the same input. In the context of generative art, this isn\u0026rsquo;t necessarily a bad thing. A minecraft world will always be the same if you give it the same seed. If we seed are random number generator with the same seed, we should get the same output every time.\nLuckily, Python comes with a Random module that we can easily use.\nimport random random.seed(1) print(random.random()) ==\u0026gt; 0.13436424411240122 On line 1, we import the random module. On line 2, we set the seed. On line 3, we ask for a random number between 0 and 1. If you are using the same interpreter as me, then you should get the same result of 0.13436424411240122. With this we will be able to generate multiple, different images using the same code. The trick will be to generate images that are different enough between seeds to be interesting. Unfortunately, I cannot find where the following analogy came from directly but I\u0026rsquo;m pretty sure it comes from Gillian Smith. A generator can produce millions of different images. The problem is that they may be like different bowls of oatmeal. I can show you two images of oatmeal and it will be very hard to say what the difference is. If the generator falls into this trap, then, for the user, it is as if the generator only produced one image of oatmeal rather than a million. For each seed, the generator should generate images that are noticeably different.\nGenerating Circles and Squares Today, we do not have the high bar of creating a generator that can make a million different images that are noticeably different. The only goal we have is to generate an image with some circles and squares. Below is all the code for the final script. Feel free to peruse, if you wish. Below we\u0026rsquo;ll go over the details and then the results. As a note, I\u0026rsquo;m starting off with this tutorial and building from there.\nfrom random import seed, randint, random from PIL import Image, ImageDraw, ImageFont TOTAL_RUNS = 4 font = ImageFont.truetype(\u0026#34;ProzaLibre-Medium.ttf\u0026#34;, size=16) for run_id in range(TOTAL_RUNS): seed(run_id) print(f\u0026#39;Processing run_id: {run_id}\u0026#39;) image = Image.new(\u0026#39;RGB\u0026#39;, (720, 480)) width, height = image.size draw_image = ImageDraw.Draw(image) for i in range(randint(30, 300)): shape_width = randint(width/10,width/5) shape_height = randint(width/10,width/5) x = randint(0, width) y = randint(0, height) if random() \u0026lt; 0.5: draw_image.ellipse([ (x, y), (x + shape_width, y + shape_height) ], fill= ( randint(0, 255), randint(0, 255), randint(0, 255), randint(0, 255) ), outline= ( randint(0, 255), randint(0, 255), randint(0, 255), randint(0, 255) ), ) else: draw_image.rectangle([ (x, y), (x + shape_width, y + shape_height) ], fill=( randint(0, 255), randint(0, 255), randint(0, 255), randint(0, 255) ) ) draw_image.text( (width-200,height-32), f\u0026#39;bi3mer :: 0002 :: {run_id + 1}/{TOTAL_RUNS}\u0026#39;, (255,255,255), align=\u0026#39;right\u0026#39;, font=font ) image.save(f\u0026#39;./output/0002_{run_id}.png\u0026#39;) On line 5, we define the font we\u0026rsquo;re going to use. Pillow does allow you to use a default font, however, you cannot change the font size. As a result, I found a free and open to use font and downloaded it. The name of the font is actually a path, so make sure to set the path to the font you decide to use correctly else Pillow will throw an error. The for loop on line 6 is so we can generate n images with n seeds.\nLine 13 declares that a new image is going to be created. I set the resolution to 720x480 but you can easily set this to 4k or even 8k. The for loop on line 17 is where we start to generate shapes. Because I want the images between seeds to be somewhat different, I have the number of shapes to be generated as random. Lines 18 and 19 are to choose how large the shapes will be, again this is random. lines 21 and 22 define where the shape will be placed. Line 24 is where it is randomly chosen to either draw a circle or a squares. If the random number generated is less than 0.5, a circle is drawn with the ellipse function. The first argument is the start x and y coordinates and the end x and y coordinates. The fill is the color of the circle and we give the RGB, three random values between 0 and 255. The last is the opacity of the shape, meaning how see-through it is. The square, after the else condition on line 42, is exactly the same except we call the function rectangle.\nThe four images above are samples of the final image we get from the python code. While we can find differences, I don\u0026rsquo;t think the generator we\u0026rsquo;ve made passes the bowl of oatmeal test. However, I do think that this is a good starting place. From here, I\u0026rsquo;m interested in lines that form a larger picture but that, as a friend of mine frequently says, feels like I\u0026rsquo;m putting the cart before the horse. As a result, I think the next step will be to generate images with The Lightning Algorithm.\n","permalink":"http://localhost:1313/posts/generative-art-circles-and-squares/","summary":"\u003cp\u003eThis is the first of what we\u0026rsquo;ll likely be a series of blog posts on generative art, specifically images. At the start, everything will be very simple. This is mainly because the topic is new to me and the library we\u0026rsquo;re going to use to generate images is also new to me. Speaking of, we\u0026rsquo;re going to be using Python and Pillow to generate images; at least at the start, we\u0026rsquo;ll see where we go. To start, I want to break this post into two parts: (1) pseudo-random and (2) generating a simple image with circles and squares.\u003c/p\u003e","title":"Generative Art: Circles and Squares"},{"content":" ","permalink":"http://localhost:1313/posts/linear-and-quadratic-discriminant-analysis/","summary":"\u003cembed src= \"/pdf/biemer_colan_LDA_and_QDA.pdf\" width= \"100%\" height= \"800\" type=\"application/pdf\" \u003e","title":"Linear and Quadratic Discriminant Analysis"},{"content":" ","permalink":"http://localhost:1313/posts/intro-to-naive-bayes/","summary":"\u003cembed src= \"/pdf/biemer_naivebayes.pdf\" width= \"100%\" height= \"800\" type=\"application/pdf\" \u003e","title":"An Introduction to Naive Bayes Classification"},{"content":" ","permalink":"http://localhost:1313/posts/deriving-ordinary-least-squares/","summary":"\u003cembed src= \"/pdf/biemer_least_squares.pdf\" width= \"100%\" height= \"800\" type=\"application/pdf\" \u003e","title":"Deriving the Ordinary Least Squares Linear Regression Solution"},{"content":" ","permalink":"http://localhost:1313/posts/motivating-the-backoff-n-gram/","summary":"\u003cembed src= \"/pdf/biemer_c_backoff_n_grams.pdf\" width= \"100%\" height= \"800\" type=\"application/pdf\" \u003e","title":"Motivating the Backoff N-Gram"},{"content":"In this post, I want to show how to implement a simple web-based typing game. A version of the final product is online; the code is on Github. The game has a menu screen where users can select whether or not to allow capitals letters and press a button to start the game. When the player begins the game, they’ll see characters—not necessarily a valid word, more an assortment of letters—to type. After the user has finished typing, the next value will be longer than the previous one. The game continues until the player mistypes. At which point, the user can see how well they did and restart.\nFinite State Machine To implement and organize the top-level behavior of the game, we are going to use a finite-state machine. A finite-state machine is a set of states and transitions where only one state can be active at a time. A state can have many transitions, both incoming and outgoing. A state defines expected behavior. A transition is a link between two states, it is not bidirectional, and it can have conditions—such as transition can only run when X is less than Y. A state cannot have multiple valid transitions at a time to guarantee deterministic behavior.\nStates At the minimum, we need three states: menu, game, and game over. The game state could be broken down into additional states like user input, check input, generate, and update UI, but this is, in my opinion, overkill as it would add complexity to the code.\nMenu State The menu state allows players to click a button to change the state and toggle whether capital letters are allowed. Capturing a button click is simple in JavaScript and is in the code below.\ndocument.getElementById(\u0026#39;startButton\u0026#39;).onclick = () =\u0026gt; { document.getElementById(\u0026#39;menu\u0026#39;).style.display = \u0026#34;none\u0026#34;; document.getElementById(\u0026#39;game\u0026#39;).style.display = \u0026#34;\u0026#34;; runGame(); }; Looking at the code block, you’ll see that there is HTML that defines a start button and two elements: menu and game. These are divs that contain each state’s HTML. When the user switches between states, one div is hidden and the other is exposed. Furthermore, there is a runGame function which we’ll look at in the game state section. For now, know that it switches the state from menu to game.\nThe other functionality is the toggle for capital letters. The link shows how to create a toggle in HTML, and now we need to save the user’s preferences. If they come back to the page, they will have their setting from before by using cookies. To set the cookie we use:\nallowCapitals = document.getElementById(\u0026#39;allowCapitals\u0026#39;).checked; document.cookie = `capitals=${allowCapitals};`; The cookie could update on changes to the toggle. In this implementation, though, the value is saved when the user exits the menu state. With the cookie stored, we can use it on startup:\n(() =\u0026gt; { const cookies = document.cookie.split(\u0026#39;;\u0026#39;); for(let cookie of cookies) { console.log(typeof cookie); if(cookie.includes(\u0026#39;capitals\u0026#39;)) { allowCapitals = cookie.split(\u0026#39;=\u0026#39;)[1] === \u0026#39;true\u0026#39; ? true : false; document.getElementById(\u0026#39;allowCapitals\u0026#39;).checked = allowCapitals; } } })(); This block of code searches for the cookie. If it finds it, it will split the cookie up to find whether or not the stored value is true or false and update the HTML. Before the game starts it will check the HTML, so there is no reason to store the value found.\nGame State In the game state, we need to handle generating words, validating input, and ending the game.\nconst characters = \u0026#39;abcdefghijklmnopqrstuvwxyz\u0026#39;; function generateNonsenseWord(size) { let string = \u0026#39;\u0026#39;; for(var i = 0; i \u0026lt; size; ++i) { let char = characters[Math.floor(Math.random() * characters.length)]; if(allowCapitals === true \u0026amp;\u0026amp; Math.random() \u0026gt; 0.5) { char = char.toUpperCase() } string += char; } return string; } This function handles the generation of nonsense words and uses a constant variable named characters that contains every letter in the alphabet. We start with an empty string and add random characters to it until it is the requested length. To capitalize, JavaScript has a convenient function toUpperCase. It is used if the user has asked for capital letters, and a random number—between 0 and 1—is greater than 0.5.\nWe can now display the word to the user. But when we do that, we want to do a bit more. In this game, the user has five seconds to input the nonsense word till they lose. To get this behavior setInterval is used; this isn’t an approach that I’d recommend, and I discuss a better, more organized way in the improvements section below.\nfunction setUpNextWord() { if(timer !== null) { clearInterval(timer); } wordIndex = 0; timeVal = 5; document.getElementById(\u0026#39;timer\u0026#39;).innerText = timeVal; timer = setInterval(() =\u0026gt; { timeVal -= 1; timeElapsed += 1; document.getElementById(\u0026#39;timer\u0026#39;).innerText = timeVal; if(timeVal \u0026lt;= 0) { endGame(); } }, 1000); wordsTyped += 1; word = generateNonsenseWord(wordsTyped + 1); document.getElementById(\u0026#39;textHere\u0026#39;).innerText = word; }; This function first clears the previously created interval if it exists. If we don’t do this, then the game will automatically terminate after five seconds have passed. Note that creating a new interval does not destroy an existing one. From there, we update the wordIndex to 0. This variable represents where in the word the user is typing. So if the user is given the word “asdf” than at 0, they are expected to type “a”. This is a cruel way of building the game because it doesn’t allow for any mistyping.\nFrom there, it updates the timeVal to 5; the user has five seconds to type the next word and the UI updates to show this. Then, an interval is created and stored. The interval will, every second, reduce the timeVal and increment the timeElapsed variable. The latter represents how long the player has played the current game session; not the total time they have had the web application open. After it will update the UI, and if the timeVal is less than or equal to 0, it will call the endGame function. After creating the interval, we increment the number of words typed—the wordsTyped variable starts at -1, so they don’t get credit for a word not yet typed—and the UI shows the next value for the user to type.\nfunction runGame() { state = \u0026#39;game\u0026#39;; timeElapsed = 0; wordsTyped = -1; allowCapitals = document.getElementById(\u0026#39;allowCapitals\u0026#39;).checked; document.cookie = `capitals=${allowCapitals};`; document.getElementById(\u0026#39;words\u0026#39;).focus(); setUpNextWord(); } Above is the second to last function related to the game state and does a few things. It updates the state and resets variables for the time elapsed and the number of words typed. You’ll recognize the next two lines of code for getting whether or not capitals are allowed and storing the result as a cookie. The next line focuses the input field; the user can type without having to click on the UI. Finally, we call the function we just described in detail, which starts the game process.\ndocument.getElementById(\u0026#39;words\u0026#39;).oninput = (data) =\u0026gt; { if(word[wordIndex] === data.data) { ++wordIndex; if(wordIndex \u0026gt;= word.length) { setUpNextWord(); } } else { endGame(); } }; This code block uses the oninput event for the input field. Every time the user types a character, this function is called. It receives an argument that has a value that represents the new keypress. We check that keypress against the expected value. If the characters match, then the word index is incremented. If that index is larger than the expected word length, a new word is set up. Else, we wait for the next input from the user or for the interval to end the game. If the input does not match the expected value, then we end the game.\nGame Over State This state displays the results from the game and has a button that the player can click to restart.\nfunction endGame() { state = \u0026#39;end\u0026#39;; if(timer !== null) { clearInterval(timer); } document.getElementById(\u0026#39;game\u0026#39;).style.display = \u0026#34;none\u0026#34;; const resultText = `You successfully typed ${wordsTyped} nonsense words in ${timeElapsed} seconds without any errors!` document.getElementById(\u0026#39;endResults\u0026#39;).innerText = resultText; } The state is updated, and the interval is destroyed. If we don’t do this then we can get into an undefined state; this is one of the reasons why intervals are not the best tool. We also change the display to the end game state. The text built says how many words the user typed in the elapsed time—the UI updates to display the text.\ndocument.getElementById(\u0026#39;restartButton\u0026#39;).onclick = () =\u0026gt; { document.getElementById(\u0026#39;end\u0026#39;).style.display = \u0026#34;none\u0026#34;; document.getElementById(\u0026#39;game\u0026#39;).style.display = \u0026#34;\u0026#34;; runGame(); }; This code restarts the game. The UI hides the end game HTML and shows the game HTML. Then the run game function is called to start the game.\nImprovements The use of intervals is problematic. There are edge-cases like the player inputting the last character at precisely 5 seconds. Will the input be called first, or will the interval be called first? As a programmer, I cannot say, and that is a problem. In a typical game engine, a loop determines the order of operations for everything. In a web-based JavaScript game, a top-level loop will freeze the browser. There is an alternative: requestAnimationFrame. It runs every frame and can call any function given as an argument; the input function receives an argument of delta time which is the time between the last call and the current call. We can now keep track of time and make the order of operations deterministic. Unfortunately, we can’t by default get a list of key presses between frames. To implement this, we would use the on keypress event to store the values in a list that can be accessed in the loop. Before the loop finishes, the last action would be to clear the list of key presses.\nConclusion In this post, I have shown you the basics of creating a simple typing game in JavaScript with HTML as a UI. The full code is available on GitHub, which is necessary as I haven’t gone through the HTML side of this. I have also shown the basics of a finite-state machine and how it can be used to organize a code-base for games. Finally, I have discussed why intervals in JavaScript are not the best tool for games, and I have gone over a more organized approach that can guarantee order of operations.\n","permalink":"http://localhost:1313/posts/typing-game/","summary":"\u003cp\u003eIn this post, I want to show how to implement a simple web-based typing game. A version of the final product is online; the code is on Github. The game has a menu screen where users can select whether or not to allow capitals letters and press a button to start the game. When the player begins the game, they’ll see characters—not necessarily a valid word, more an assortment of letters—to type. After the user has finished typing, the next value will be longer than the previous one. The game continues until the player mistypes. At which point, the user can see how well they did and restart.\u003c/p\u003e","title":"Typing Game"},{"content":"If it were up to me, every website would be required to have a theme option of light or dark. Unfortunately, it is not. It is uncommon to find websites that include both options or, at least, default to dark mode. Recently FaceBook included a dark mode option and slack now has it built into their app. It is a wonderful thing to see it become more popular. Still, there is no guarantee. As a result, I have turned to Dark Reader. A great chrome extension that will automatically run on all websites but gives you the option to turn off it completely or turn off for certain websites.\nIt is not a perfect solution, though. On some websites, it won’t work as expected and you are stuck going through the website in a light version; a very jarring experience when coming from a dark screen. As a result, I used a chrome extension that inverted colors. The problem with the extension was twofold. First, it didn’t work on local pdfs. Second, I didn’t know who the developer was and if I could trust them. Because of this, I built my own chrome extension and put it on GitHub.\nBefore looking at building a chrome extension, we need to be able to invert chrome colors. Luckily, someone has already done the work. A quick search and there was an answer on [StackOverflow(https://stackoverflow.com/questions/4766201/javascript-invert-color-on-all-elements-of-a-page/16239245#16239245)]. No work needed. All I did was open a webpage and run it in the console to make sure it worked.\nWith this, we can build the extension. At the minimum, an extension needs a manifest.json file and some javascript file that the manifest can call. The manifest file is the following:\n{ \u0026#34;manifest_version\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;invert\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;2020.04.29\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Invert screen colors.\u0026#34;, \u0026#34;browser_action\u0026#34;: {}, \u0026#34;background\u0026#34;: { \u0026#34;scripts\u0026#34;: [\u0026#34;background.js\u0026#34;], \u0026#34;persistent\u0026#34;: false }, \u0026#34;permissions\u0026#34;: [ \u0026#34;http://*/\u0026#34;, \u0026#34;https://*/\u0026#34; ] } As you can see, we need to give a manifest_version, for some reason it had to be greater than one. The name can be anything; I chose invert. The version was the date I made it and the description should likely be more descriptive if you plan on publishing. I gave it no browser action. In the background I have it call the script background.js and note that the call is not persistent. This is where we could be malicious and, for example, set persistent to true and log the user’s keystrokes. Finally, we have the permissions that the extension asks for. In this case, we start by only asking for permission to modify webpages. We’ll come back to this later.\nThe next question you are probably asking is: what is background.js?\nchrome.browserAction.onClicked.addListener(function(tab) { chrome.tabs.executeScript(null, {file: \u0026#34;invert.js\u0026#34;}); }); If we use invert.js—which contains the inversion code from StackOverflow—instead of background.js then the webpage will not be modified. If we place the inversion code in the callback function and do not call chrome.tabs.executeScript(...) then the webpage will also not be modified. The function of background.js is to call the file that inverts the webpage and that is it. Likely there is another way to use chrome.tabs such that two files are not necessary but I did not find it.\nWe have three files: manifest.json, invert.js, and background.js which form the entire chrome extension. To build the extension, follow these steps:\nGo to chrome://extensions/ in your chrome browser. In the top right there is a developer switch. Switch it to on. Click the button in the top left titled “load unpacked”. Select the folder which contains these three files. You now will have a new extension that will be a small block with the letter “i” in it. By modifying the manifest.json you can include your own image as the icon if you like. When you click the new button the page will invert. If you open a local pdf, the page will not invert. This is because we did not give it permissions for local files, only websites. Modify the manifest.json permissions to include \u0026ldquo;file://*\u0026rdquo; in the JSON array. If you click on the invert button again you will see that the change has not yet been registered. Go back to the chrome extension page and click the refresh arrow under the invert extension. The invert on the local pdf will now work.\n","permalink":"http://localhost:1313/posts/chrome-invert-colors/","summary":"\u003cp\u003eIf it were up to me, every website would be required to have a theme option of light or dark. Unfortunately, it is not. It is uncommon to find websites that include both options or, at least, default to dark mode. Recently FaceBook included a dark mode option and slack now has it built into their app. It is a wonderful thing to see it become more popular. Still, there is no guarantee. As a result, I have turned to \u003ca href=\"https://darkreader.org/\"\u003eDark Reader\u003c/a\u003e. A great chrome extension that will automatically run on all websites but gives you the option to turn off it completely or turn off for certain websites.\u003c/p\u003e","title":"Chrome Invert Colors"},{"content":"Let\u0026rsquo;s start by examining the simplest case of joint probability with single word probability via a uni-gram. If we want to know the probability of a word, without any context appearing before or after, then we could take a corpus of text and convert it into a dictionary with the key for the word and the count as the value: { \u0026quot;a\u0026quot;: 1000, \u0026quot;an\u0026quot;: 3, \u0026quot;animal\u0026quot;: 12, ... }. Say we want to calculate P(\u0026quot;a\u0026quot;), meaning the likelihood of \u0026ldquo;a.\u0026rdquo; We would take the count of occurrences for the word \u0026ldquo;a\u0026rdquo; and divide it by the total number of words in the corpus: P(\u0026quot;a\u0026quot;) ≈ count(\u0026quot;a\u0026quot;) / corpus_word_count. This is called maximum likelihood estimation (MLE) and we use the \u0026ldquo;≈\u0026rdquo; sign because our corpus is not a perfect representation of the actual likelihood of the word.\nSay we wanted to calculate the probability of \u0026ldquo;an animal\u0026rdquo;. In this case we would have P(\u0026quot;an animal\u0026quot;) ≈ P(\u0026quot;an\u0026quot;)P(\u0026quot;animal\u0026quot;) because the relationship between \u0026ldquo;an\u0026rdquo; and \u0026ldquo;animal\u0026rdquo; is independent for our model; this is not true for the english language which is why we use the approximately equals sign. With the independence we can now calculate the probability with the chain rule:\nP(\u0026#34;an animal\u0026#34;) ≈ P(\u0026#34;an\u0026#34;)P(\u0026#34;animal\u0026#34;) = (count(\u0026#34;an\u0026#34;)/corpus_word_count) * (count(\u0026#34;animal\u0026#34;)/corpus_word_count) Now that we understand joint probability with uni-grams, we can generalize our knowledge to work with any n-gram where n is an integer and greater than 0. To begin, let\u0026rsquo;s look at the sentence, \u0026ldquo;An animal dropped from the tree.\u0026rdquo; Say we have a trained bi-gram ready to calculate the likelihood of the sentence. What would it do for the first word? The bi-gram needs to have the word that occurred before \u0026ldquo;An\u0026rdquo; to work. One way to get around this problem is build n-grams with tokens at the beginning and end of a sentence, \u0026ldquo;\u0026lt;s\u0026gt; An animal dropped from the tree \u0026lt;/s\u0026gt;.\u0026rdquo; Note, if if this was a tri-gram there would be two start of sentence tokens instead of one. In our case, though, we are interested in being able to generate more than one sentence. Instead, we calculate the probability of the first word with a 1-gram, then the second word with a bi-gram, and so on for whatever n. Instead of a bi-gram here is the formulation of how a tri-gram calculates joint probability:\nP(S) ≈ P(s1)P(s2|s1)P(s3|s1,s2)...P(sn|sn-2,sn-1) If it was a bi-gram the last calculation would be P(sn|sn-1). If it was a quad-gram it would be P(sn|sn-3,sn-2,sn-1). There is, however, a potential problem with this formulation when we move away from theory and towards computation: underflow. Underflow occurs when the resulting calculation of an operation is a number smaller than the computer can represent. With our current method of joint probability calculation we multiply a bunch of, potentially, small decimals together and could run into underflow. To avoid some of these inaccuracies we can run the calculation in log space, and to do so we need to know the following identity:\nlog(x1*x2*...*xn) = log(x1) + log(x2) + ... + log(xn) This identity tells us that we can take any multiplication and turn it into an addition problem which will reduce the likelihood of encountering extremely small numbers. In addition, adding is a faster operation than multiplication. With the identity, we can calculate our joint probability by first adding all the individual log probabilities and raising e by the result to get a probability of higher accuracy.\n\\[ \\begin{aligned} P(W) ≈ e ^{log(P(W1)) + log(P(W2|W1)) + ...} \\end{aligned} \\]In addition to the formulation, I have implemented this on github and you\u0026rsquo;ll notice that there is an extra check for the probability of zero occurring because zero is undefined for log. However, if one of the probability calculations ends up being zero then we know the resulting probability will be zero.\n","permalink":"http://localhost:1313/posts/n-gram-joint-probability/","summary":"\u003cp\u003eLet\u0026rsquo;s start by examining the simplest case of joint probability with single word probability via a uni-gram. If we want to know the probability of a word, without any context appearing before or after, then we could take a corpus of text and convert it into a dictionary with the key for the word and the count as the value: \u003ccode\u003e{ \u0026quot;a\u0026quot;: 1000, \u0026quot;an\u0026quot;: 3, \u0026quot;animal\u0026quot;: 12, ... }\u003c/code\u003e. Say we want to calculate \u003ccode\u003eP(\u0026quot;a\u0026quot;)\u003c/code\u003e, meaning the likelihood of \u0026ldquo;a.\u0026rdquo; We would take the count of occurrences for the word \u0026ldquo;a\u0026rdquo; and divide it by the total number of words in the corpus: \u003ccode\u003eP(\u0026quot;a\u0026quot;) ≈ count(\u0026quot;a\u0026quot;) / corpus_word_count\u003c/code\u003e. This is called maximum likelihood estimation (MLE) and we use the \u0026ldquo;≈\u0026rdquo; sign because our corpus is not a perfect representation of the actual likelihood of the word.\u003c/p\u003e","title":"N-Grams: Joint Probability"},{"content":"In my last post I discussed n-grams and gave an example of them being used on the text of Harry Potter but I didn\u0026rsquo;t cover the implementation and instead linked the source. Today, I want to go over a key data structure used in my implementation: ring buffers (also known as a circular buffer).\nA ring buffer needs a max size, N, that represents its max capacity. Until the buffer has reached its max capacity, it is exactly like a list. However, once the max capacity is reached the buffer will drop elements when new ones are added resulting in a first in first out (FIFO) behavior. An example of this data structure in action can be seen below. We initialize a ring buffer of size three. At first the ring buffer acts like a list but stops when the fourth element is added. On this add, the ring buffer drops the 0 because it was the first element added and the buffer has reached its max capacity of three. Say, for example, we ran this again and added a four. The buffer would then be [2,3,4] because the one would be the next element to be dropped.\n\u0026gt;\u0026gt;\u0026gt; from DataStructures import RingBuffer \u0026gt;\u0026gt;\u0026gt; rb = RingBuffer(3) \u0026gt;\u0026gt;\u0026gt; rb.buffer [] \u0026gt;\u0026gt;\u0026gt; rb.add(0) \u0026gt;\u0026gt;\u0026gt; rb.buffer [0] \u0026gt;\u0026gt;\u0026gt; rb.add(1) \u0026gt;\u0026gt;\u0026gt; rb.buffer [0, 1] \u0026gt;\u0026gt;\u0026gt; rb.add(2) \u0026gt;\u0026gt;\u0026gt; rb.buffer [0, 1, 2] \u0026gt;\u0026gt;\u0026gt; rb.add(3) \u0026gt;\u0026gt;\u0026gt; rb.buffer [1, 2, 3] Now that we have an idea of how the ring buffer is supposed to behave, we can implement it. The first thing we should do is define are initialization function for the class. In this case, we know that we must receive N but don\u0026rsquo;t need anything else from the user.\ndef __init__(self, buffer_limit): self.buffer_limit = buffer_limit self.buffer = [] With our buffer and size handled in the initialization, we can then go into the important function of the buffer: add. This is the function that implements the circular behavior we saw above. To do this we have first have to check whether or not the array is full by using N and comparing it to the length of the buffer. If the buffer has reached max capacity then we remove the first element of the buffer with self.buffer.pop(0). Afterwards, we can then add the value to the buffer by appending it to the end.\ndef add(self, value): if self.full(): self.buffer.pop(0) self.buffer.append(value) def full(self): return len(self.buffer) == self.buffer_limit You can also add additional functions like get as a way to get individual elements from the buffer by index which can be seen in the source implementation. There is also a great implementation on github that a good friend of mine coded in C#. The code I have provided is not the most efficient implementation of the data structure but does, in my opinion, get across the way it is supposed to function best. It is a data structure that I use fairly regularly and wish came with languages but since it does not I recommend to most programmers to learn about it and how to implement it. It\u0026rsquo;s a very good tool to have in the toolbox.\n","permalink":"http://localhost:1313/posts/ring-buffer/","summary":"\u003cp\u003eIn my \u003ca href=\"../harry-potter-n-grams/\"\u003elast post\u003c/a\u003e I discussed n-grams and gave an example of them being used on the text of Harry Potter but I didn\u0026rsquo;t cover the implementation and instead linked the source. Today, I want to go over a key data structure used in my implementation: ring buffers (also known as a circular buffer).\u003c/p\u003e\n\u003cp\u003eA ring buffer needs a max size, \u003ccode\u003eN\u003c/code\u003e, that represents its max capacity. Until the buffer has reached its max capacity, it is exactly like a list. However, once the max capacity is reached the buffer will drop elements when new ones are added resulting in a first in first out (FIFO) behavior. An example of this data structure in action can be seen below. We initialize a ring buffer of size three. At first the ring buffer acts like a list but stops when the fourth element is added. On this add, the ring buffer drops the 0 because it was the first element added and the buffer has reached its max capacity of three. Say, for example, we ran this again and added a four. The buffer would then be \u003ccode\u003e[2,3,4]\u003c/code\u003e because the one would be the next element to be dropped.\u003c/p\u003e","title":"Ring Buffers"},{"content":"I recently started grad school and one of the classes I am taking is Natural Language Processing (NLP). Before the class I decided to watch a few videos on NLP and came across N-Grams. I have not made it known in any of my past posts but I love N-Grams. One of my projects is around reinforcing N-Grams which I hope to post about sometime later this year. Digression aside, I decided it would be a fun project to write an n-gram that uses the text of Harry Potter as input and see what we get; I know it isn\u0026rsquo;t the most original idea but it was fun.\nBefore we can get into the results, let\u0026rsquo;s go over n-grams. The \u0026ldquo;n\u0026rdquo; in n-gram is meant to represent some integer greater than 0. The \u0026ldquo;gram\u0026rdquo; is short for grammar. When you put it together you get a grammar that takes an input of size n and returns the word that is likely to be next. Let\u0026rsquo;s take a small example sentence to show the concept, \u0026ldquo;Colan was here yesterday and was here today.\u0026rdquo; With this example let\u0026rsquo;s construct a n-gram where n is equal to two.\nTo parse this sentence for a n-gram of size two, the first input is \u0026ldquo;Colan was\u0026rdquo; and the result is \u0026ldquo;here.\u0026rdquo; Meaning when the grammar receives the phrase \u0026ldquo;Colan was\u0026rdquo; the grammar will expect the next word to be \u0026ldquo;here.\u0026rdquo; So let\u0026rsquo;s show what the grammar looks like at this phase.\n{ \u0026#34;Colan was\u0026#34;: { \u0026#34;here\u0026#34;: 1 } } You\u0026rsquo;ll notice that we have \u0026ldquo;here\u0026rdquo; correspond to the value of one. This is because we are currently parsing the input and keeping track of the number of occurrences. When we are done setting up our input we can compile the grammar into something that will predict the next output. But more on that after we are done counting the occurrences. The next set of input is \u0026ldquo;was here\u0026rdquo; with the result of \u0026ldquo;yesterday\u0026rdquo;. Following that you will get \u0026ldquo;was yesterday\u0026rdquo; corresponding to \u0026ldquo;and.\u0026rdquo; This will go on until we get the final result below.\n{ \u0026#34;Colan was\u0026#34;: { \u0026#34;here\u0026#34;: 1 }, \u0026#34;was here\u0026#34;: { \u0026#34;yesterday\u0026#34;: 1, \u0026#34;today\u0026#34;: 1 }, \u0026#34;here yesterday\u0026#34;: { \u0026#34;and\u0026#34;: 1 }, \u0026#34;yesterday and\u0026#34;: { \u0026#34;was\u0026#34;: 1 }, \u0026#34;and was\u0026#34;: { \u0026#34;here\u0026#34;: 1 } } Now that we have created a grammar that counts all the occurrences we can compile it which means we can turn it into a set of probabilities. There are two ways to do this, weighted and unweighted. What I call the unweighted approach is one where the occurrences are ignored and each potential value is given the same weight. In this case we would take \u0026ldquo;was here\u0026rdquo; and automatically apply 0.5 to both values regardless of how many occurrences there actually were. The weighted approach is one where we do use the occurrences and calculate each value by dividing the values occurrences by the number of occurrences for the key. In our example, both the weighted and the unweighted versions are the same.\n{ \u0026#34;Colan was\u0026#34;: { \u0026#34;here\u0026#34;: 1 }, \u0026#34;was here\u0026#34;: { \u0026#34;yesterday\u0026#34;: 0.5, \u0026#34;today\u0026#34;: 0.5 }, \u0026#34;here yesterday\u0026#34;: { \u0026#34;and\u0026#34;: 1 }, \u0026#34;yesterday and\u0026#34;: { \u0026#34;was\u0026#34;: 1 }, \u0026#34;and was\u0026#34;: { \u0026#34;here\u0026#34;: 1 } } With this compiled version we can now use this grammar to predict the next word and generate some interesting text. In our case we can use the input \u0026ldquo;Colan was.\u0026rdquo; Looking at the compiled grammar we know the value given back is \u0026ldquo;here.\u0026rdquo; However, if we continued it would then take \u0026ldquo;was here\u0026rdquo; and return either \u0026ldquo;today\u0026rdquo; or \u0026ldquo;yesterday\u0026rdquo; with both having a fifty percent chance. If we continued it would generate something like, \u0026ldquo;Colan was here yesterday and was here yesterday and was here yesterday and was here today.\u0026rdquo; Notice that once we get to \u0026ldquo;today,\u0026rdquo; it can no longer generate anything.\nThis example, while small, shows the strengths and weakness of n-grams. It is an incredible structure that can quickly mimic style and technique used in the input to produce interesting but similar results. The larger the n, the more sensible the output will be as well as the more similar it will be to the input. On the other hand, it is limited by its very strengths. Ultimately we want AI to generate new and interesting things which n-grams can inherently not do.\nNow that we, hopefully, understand n-grams we can get to what happens when we apply n-grams of sizes one to six on the first two books of Harry Potter. If you would like to see my implementation of this you can see the source on github. I think you can see that the weighted versions of the grammar tend to read a bit more sensibly, especially when n is lower. You\u0026rsquo;ll also notice that n-grams can have trouble with quotes, especially when they are long and use commonly found phrases.\nN=1 Unweighted Output for the first time in his body . hang glider on nettle wine’s left on “don’t — thing left.” he grunted into glowing in him norbert,” said “hello nick,” said uncertainly. “a boa constrictor’s tank and scared. “what really there is?” “i repeat if that’s it simply waved it out.” harry “because being one thought you speak about anything justin might think!” harry joined them weren’t nearly killed ’em. horribly. “yes exactly. i expect,” said “but they weren’t. he handed it also bring silence. the desk just managing to trundling around unseen.” harry loaded into any moment hedwig soared back out gryffindor ghost began to detect\nWeighted Output for the first time in his muggle shop without ending with our own house!” harry watched the great glinting emeralds. harry remembered that ruddy stargazers. not say anything missing?” harry looked as he was always was on in front page were there stood there was disheveled. ignoring her put him what mcgonagall transfigured or tickled them inside. hermione remained of slytherin wished he threw him as paving stones bound to a soft voice. “and women,” wood and the diary. all that ter pay for the faintest sound. where the entrance hall. “just been sent me.” feeling about you must be those bits of books into applause\nN=2 Unweighted Output for the first time in his throat — i then screwed up his robes was what looked like bodyguards. “oh this doesn’t often happen at hogwarts — i only hope we can get something of the few owls that managed to beat away. mr. weasley passing harry and malfoy barely inclined their heads not taking his eyes as narrow as he handed uncle vernon came in harry. you found it inside one of our kind underwent so many students filed past the giant serpent uncoiling itself rapidly slithering out onto the platform?” she said sharply. “why?” “funny stuff on the mantelpiece. george groaned. “mum we know\nWeighted Output for the first time in his tracks and harry were up in his hand. “i’ve got to go to hogwarts.” uncle vernon held it up there — ” “was that you?” said harry “but what’s curious?” mr. ollivander was flitting around the room was almost dark now but i got back from the dog was guarding the stone.” harry looked up at the end of a wizard’s duel?” said harry. nearly headless nick and madam pomfrey told me in the bedroom window and passed it out flicked it open and pulled his wand and turned to stare at the troll stopped next to the entrance hall.\nN=3 Unweighted Output for the first time in his life. he was hungry he’d missed five television programs he’d wanted to see me professor dippet?” said riddle. he looked nervous. “sit down,” said harry politely pointing at the topmost pane where around twenty spiders were scuttling apparently fighting to get through all their extra work. “i’ll never remember this,” ron burst out one afternoon throwing down his quill in a transport of rage. “i’ll have you this time i’ll have you!” and without a backward look. then dented scratched and steaming the car rumbled off into the night. “i shall see you soon i expect professor mcgonagall,” said hagrid.\nWeighted Output for the first time in his life until a month ago and he told ron and hermione had brought out of the hall hermione hurrying alongside them. as they went upstairs to meet ron in the library with her trying to get near enough to hear what they were saying. their mother had just taken out her handkerchief. “ron you’ve got something on your nose.” the youngest boy tried to jerk out of the troll’s hand rose high high up into the giant face above it was ancient and monkeyish with a long white finger. “i’m sorry to say i sold the wand that did it,”\nN=4 Unweighted Output for the first time in his life harry was pleased to hear the note of panic in his voice. “yeh are if yeh want ter stay at hogwarts,” said hagrid fiercely. “yeh’ve done wrong an’ now yeh’ve got ter pay fer it.” “but this is servant stuff it’s not for students to do. i thought we’d be copying lines or something if my father knew i was doing this he’d — ” “ — is the golden snitch,” said harry “and it’s very small very fast and difficult to see. it’s the seeker’s job to catch it. you’ve got to weave in and out of focus.\nWeighted Output for the first time in his life a high cold cruel laugh. hagrid was watching him sadly. “took yeh from the ruined house myself on dumbledore’s orders. brought yeh ter this lot \u0026hellip;” “load of old tosh,” said uncle vernon. harry jumped he had almost forgotten that the dursleys were there. uncle vernon certainly seemed to have changed her mind about snape. “i know a jinx when i see one hagrid i’ve read all about them.” ron dropped his wand. hermione granger telling a downright lie to a teacher “if they hadn’t found me i’d be dead now. harry stuck his wand up its nose and\nN=5 Unweighted Output for the first time in his life. his aunt and uncle hadn’t been able to think of anything else to do with him but before they’d left uncle vernon had taken harry aside. “i’m warning you,” he had said putting his large purple face right up close to harry’s “i’m warning you now boy — any funny business anything at all — and you’ll be in that cupboard from now until christmas.” i’m not going to do anything,” said harry “honestly but uncle vernon didn’t believe him. no one ever did. the problem was strange things often happened around harry and it was just no good\nWeighted Output for the first time in his life. his aunt and uncle hadn’t been able to think of anything else to do with him but before they’d left uncle vernon had taken harry aside. “i’m warning you,” he had said putting his large purple face right up close to harry’s “i’m warning you now boy — any funny business anything at all — and you’ll be in that cupboard from now until christmas.” i’m not going to do anything,” said harry “honestly but uncle vernon didn’t believe him. no one ever did. the problem was strange things often happened around harry and it was just no good\nN=6 Unweighted Output for the first time in his life. the potters smiled and waved at harry and he stared hungrily back at them his hands pressed flat against the glass as though he was hoping to fall right through it and reach them. he had a powerful kind of ache inside him half joy half terrible sadness. how long he stood there he didn’t know. the reflections did not fade and he looked and looked until a distant noise brought him back to his senses. he couldn’t stay here he had to find his way back to bed. he tore his eyes away from his mother’s face whispered\nWeighted Output for the first time in his life a high cold cruel laugh. hagrid was watching him sadly. “took yeh from the ruined house myself on dumbledore’s orders. brought yeh ter this lot \u0026hellip;” “load of old tosh,” said uncle vernon. harry jumped he had almost forgotten that the dursleys were there. uncle vernon certainly seemed to have got back his courage. he was glaring at hagrid and his fists were clenched. “now you listen here boy,” he snarled “i accept there’s something strange about you probably nothing a good beating wouldn’t have cured — and as for all this about your parents well they were weirdos\n","permalink":"http://localhost:1313/posts/harry-potter-n-grams/","summary":"\u003cp\u003eI recently started grad school and one of the classes I am taking is Natural Language Processing (NLP). Before the class I decided to watch a few videos on NLP and came across N-Grams. I have not made it known in any of my past posts but I love N-Grams. One of my projects is around reinforcing N-Grams which I hope to post about sometime later this year. Digression aside, I decided it would be a fun project to write an n-gram that uses the text of Harry Potter as input and see what we get; I know it isn\u0026rsquo;t the most original idea but it was fun.\u003c/p\u003e","title":"N-Grams With Harry Potter"},{"content":"A few months ago I completed the annual ProcJam jam. I wish I had considered doing a postmortem beforehand when everything was fresh, but now I am preparing for 7DRL. I figure a retrospective on how I did in the last jam will be useful for the upcoming one.\nBefore beginning, I would like to preface this with the fact that I was sick for the entire jam. It’s not an excuse but it is one of the reasons why I did not complete as much as I would have liked to in the game. My original design was a weapon based roguelike, minus turn-based, where the player is trying to get through as many levels as possible. The weapons would be dropped by enemies and they would be adversarially generated. Meaning, a player that spams weapon shots would receive guns that shoot slower. A player that was extremely accurate would receive guns that would spray, such as a shotgun. In addition, all levels would be procedurally generated. I hoped to get in a few enemies and had a stretch goal of creating a boss. Lastly, I hoped to make the game a platformer. In short, I had an ambitious scope for a ten-day jam even if I wasn’t sick.\nOn my first night working on the project, I set up the project and built a basic scene to show player movement and basic shots. There wasn’t anything special being done here, however, I did waste time playing with variables to make jumping feel right. I say it was a waste of time because it is more important to get functionality in a jam than polish. At this point, I was feeling fine about my scope but half nervous about level generation. I didn’t, and still don’t, know a great way to procedurally generate compelling platformer levels.\nOn day two Trevor, someone who worked with me on the project, improved the shooting code I wrote the day before and improved player movement. I started the night by implementing a basic enemy framework. Where the BaseEntity had a few stats, like health and functions to handle damage, and other classes implemented on top of it. For example, the BaseEnemy inherited from the BaseEntity and added dropping loot to the entity. At the end of the enemy implementation, I added a single enemy that would fly towards you and explode on impact. In addition, I also added room generation which convinced me that the current platformer idea was too much of a stretch for the jam.\nThe generation was pretty simple. I set up a MonoBehavior class which I knew would handle multiple kinds of generation but at the moment would be hardcoded with the one generation method. The generation method I implemented was very simple. Start with a matrix of all dead cells. Turn the bottom leftmost cell alive, the starting point, and find points that it can explore. In this case, it will be moving up one cell or to the right. Both of these are added as leaves and the algorithm chooses a random leaf. The newly explored leaf will check dead cells with the constraint that this dead cell cannot be next to any alive cells in the four cardinal directions. After the new leaves are added, the explored cell is turned alive and it repeats until the top rightmost cell is turned on.\nFigure 1: Example level generated with the randomly explored branching tree method The results of the algorithm can be seen in figure 1 and it shows a few flaws in the generation. The first flaw is that the left side will always be more explored than the right side. The second is that it only creates corridors. The third is that the algorithm does not guarantee exploration to the top right as described. It is easy to fix with a special case where we check if the second most top right point is turned alive, if so then we finish the path by hardcoding. However, it is a flaw in the algorithm. Regardless of these flaws, the first mistake was not having the generation method planned ahead of time for the jam. At this point, I was still thinking about doing a platformer and this method clearly doesn’t work for a platformer and does not create interesting levels.\nOn day three, Trevor moved the structure of enemies, and the player, to an entity component system. Classes are broken down to pieces and avoid an inheritance headache that comes from the system I built the day before for entities. In addition, he implemented a tougher enemy that took the kamikaze bot I created and set it up so it would ram into you and do damage. After you’ve done enough damage to kill it, it had eight eggs around it hatch and eight kamikaze enemies came after you. It was a solid display of the strengths of the entity component system and was a fun enemy to play against.\nI started off the day by fixing the error in my generation code where the top right was not reached with the special case I mentioned above. I then improved the level generation by adding two noise functions based on Conway’s Game of life. The first was a direct implementation of the algorithm where you could choose the number of epochs and can be seen in figure three. The second was Conway’s Game of Life with the killing cells removed and can be seen in figure two. The noise function used is applied to the generated level after the first generation method carved out the map.\nEpochs: 1 Epochs: 2 Epochs: 5 Epochs: 10 As can be seen above, Conway keep alive creates maps that aren’t that interesting and fairly open. The regular Conway noise, figure three, creates interesting looking maps but doesn’t guarantee a path after two epochs. Even at two epochs, it isn’t a sure thing.\nEpochs: 1 Epochs: 2 Epochs: 5 Epochs: 10 At this point, I knew my dreams of making the game a platformer would not be realized. So for my last act of the night, I removed the platformer scripts and reimplemented movement for a top-down game. Luckily nothing had to be done to the rest of the enemies since they were still fairly simple.\nOn day four Trevor updated the Unity version of the project and changed the generation to use tilemaps instead. Before I had been placing them in space with code. Now the tilemap handled the placing for us. I started by removing single dead cells. Meaning that if a tile was surrounded by alive cells it was turned alive. It made the maps a bit easier to navigate and feel a lot better. I then added a UI for health so the player can see their health on the screen. This also made it much easier to confirm that enemies were doing damage as intended. After that, I added a pause menu to the game.\nFigure 2: Example map with new tiles and a fun bug On day five Trevor became an artist and replaced my white and black tiles with a simple tilemap; the results can be seen in Figure 2. You can also see a fun bug where there was no cap on the players shooting speed. I then implemented A* in the game. It wasn’t hard since it feels like I’ve implemented it a thousand times. Though it does take some time, and, in this case, it was time completely wasted.\nFigure 3: A* example on generated map I wanted to use A* to guarantee pathing for level generation. I wanted to use it for enemies. I wanted to use it but never had the time to. It was time that was completely wasted. In a jam like this, especially when sick and during a work week, time wasted is huge. I think it’s one of the main reasons that I never did end up getting to work on the adversarial weapons. Mistakes aside, I added a start screen with a basic menu. Then I set up level incrementing so when the player died they’d go back to level 1. I still did not have any ability for the player to move up a level at this point.\nI started off day six by adding quit buttons to the main menu and the pause menu in the game. I also fixed a bug where the level generation would run infinitely. It was very rare and I never did figure out why it occurred. As a band aid, I set it up so it returned a null value and then the level generation algorithm would be called again. It was a lazy solution, but necessary given the time constraints.\nFigure 4: an example of the game loop with ladders. After I got started on adding ladders to the game so there was a full game loop, see figure 6. It wasn’t that hard to implement. When the player came in contact with the ladder, the level would be incremented and the scene reloaded. I didn’t add any requirements for the player to kill every enemy before she could advance. It was something I considered for the future, but not the first iteration of the game.\nThe last thing I did on day six was add a spawner to the game. It was fairly simple. At the start of every level, the spawner would see what level the player was on and multiply the amount by 4 and divide the result by 1.5. The ceiling of that value was how many enemies would spawn. I came up with the numbers by playing with variables until something felt right and the plot looked reasonable. To choose spots for enemies to spawn, I chose random positions that were a minimum distance from the player. I kept a hashtable of all the used positions. Once every enemy had a place to spawn, they were placed. I also set up three arrays of enemies: easy, medium, and hard. The next day I planned to make it so higher tiered enemies would count for more when spawning.\nDay 7 was the last day of the jam and I was in trouble. Technically, the jam lasts for 10 days but I hadn’t been well enough to compete for three days. I also had a lot to do. I still didn’t have any weapons being generated or any sense of progression as you moved through the game. I started off by implementing player death. I did this by having the player go back to the main menu which would auto reset the level to 1 every time.\nAfterward, I moved onto updating the generation so all three corners of the map could be where the ladder spawned instead of just the top right. I didn’t update the generation method for this. Instead, I checked if the top left and bottom right corners were available for ladder spawning. If they were I added them to an array and choose randomly from the array. This is one of those things I’m happy I added but was not essential. It was a waste of time when I still needed to add something like weapons.\nIn hindsight, at this point, I had given up on the weapons. I was already considering using the entity components used for enemies as a way to enhance player attributes. While considering this I improved the enemy generation to now use the tiered approach I discussed above. I also took away the hardcoded multiple arrays and made it an array of arrays to be more dynamic and useful if I decided to continue working on the game.\nFollowing the improvement to spawning, I added the third and final enemy the game would ever see: the pest. The pest was the exact same as the kamikaze enemy but it would not explode on impact, instead do damage, and it could fly over obstacles. It is truly a pest and a very annoying enemy in the game. It is small enough so hitting it is kind of hard. Overall, I’m a big fan of the pest.\nFigure 5: Level generator UI Next up, was my biggest mistake seen in Figure 5. Because this was ProcJam I wanted to show off the procedural generation with a UI that showed all the noise functions. However, the game should have done this on its own without the help of this extra UI. I enjoyed making it, but it was a complete waste of time and did not add any value to the end result.\nMy last act for the game was to add progression to the player’s character. I updated the enemy loot system so each destroyed enemy would drop a box. Each box represented a different stat: health, fire rate, damage, movement speed, and shot lifetime. Unfortunately, I didn’t communicate to the player at all what each box represented. Or do anything to clarify that the boxes were good. But I did set up a Ratchet and Clank bolts like collection system where they just flowed into you. Setting up the components to interact with the player was already implemented thanks to the entity component system. And whenever a new box was added, it added another component to the player.\nOnce the player had defeated the level, all the components for each stat type were added up and saved. On load, the stats would be added up into one big component and the process would restart. On entering the main menu the stats would be set back to one. Setting up the saving was a bit more complicated than I would have liked but overall was not too horrible to get right.\nAnd that is the process I had for ProcJam 2018. My main takeaway is that I wasn’t focused enough on the MVP. I wanted to get adversarial weapon selection but didn’t have time because I didn’t have a plan going into the development. That is why for 7DRL I am planning for it now. When it comes time for development, I want to know exactly what I am going to be making. I want to know the technology I’m going to use. I want to know the procedural generation techniques I’ll be using. I want to have as many components of the game, application, etc. planned as possible for any future jam I participate in.\n","permalink":"http://localhost:1313/posts/procjam-2018-postmortem/","summary":"\u003cp\u003eA few months ago I completed the annual \u003ca href=\"https://www.procjam.com/\"\u003eProcJam\u003c/a\u003e jam. I wish I had considered doing a postmortem beforehand when everything was fresh, but now I am preparing for \u003ca href=\"http://www.roguebasin.com/index.php?title=7DRL\"\u003e7DRL\u003c/a\u003e. I figure a retrospective on how I did in the last jam will be useful for the upcoming one.\u003c/p\u003e\n\u003cp\u003eBefore beginning, I would like to preface this with the fact that I was sick for the entire jam. It’s not an excuse but it is one of the reasons why I did not complete as much as I would have liked to in the game. My original design was a weapon based roguelike, minus turn-based, where the player is trying to get through as many levels as possible. The weapons would be dropped by enemies and they would be adversarially generated. Meaning, a player that spams weapon shots would receive guns that shoot slower. A player that was extremely accurate would receive guns that would spray, such as a shotgun. In addition, all levels would be procedurally generated. I hoped to get in a few enemies and had a stretch goal of creating a boss. Lastly, I hoped to make the game a platformer. In short, I had an ambitious scope for a ten-day jam even if I wasn’t sick.\u003c/p\u003e","title":"Procjam 2018 Postmortem"},{"content":"I want to go over Q-learning (a form of reinforcement learning) in this post. To start, we could go in two directions. We could explore at the bottom and look at the math behind neural networks and Q-learning. Or we could start at the top and see the end result. We are going to go with the latter.\nFigure 1: The mountain car environment. To do this we are going to need a few libraries and a testbed. To test, we are going to use OpenAI’s Gym and use MountainCar-V0. In this environment, proposed by Andrew Moore in his Ph.D. thesis, the car must reach the flag seen in figure 1. The car, though, does not have enough acceleration to achieve this by just going forward. Instead, it must go back and forward, steadily gaining enough speed to reach the goal. This is a problem that can be solved simply with a rule-based agent, however, reinforcement approaches can struggle with this. You’ll soon see that the amount of episodes it takes for q-learning to solve this is more than expected.\nWe are going to need to install gym, keras, and keras-rl. All of these can be installed with pip install X. I would recommend using anaconda when possible. Keras is a library built to use TensorFlow, CNTK, or Theano. Each of these three are neural network libraries that we can use to define networks. Keras makes it easy to use any of these and provides a very intuitive way to define networks. Also, when installing Keras it may be configured to use a library for neural networks you do not want to use; if you encounter this issue, please visit this site. Keras-RL is a reinforcement learning library built on top of Keras which allows us to run reinforcement algorithms on Keras networks for any gym environment. Meaning, the code is incredibly simple for this post. As a note, TensorFlow does provide Keras built in, but this will not work with Keras-RL. You need to use Keras for this stage.\nWith that done, we can start building our example without having a clue about anything we’re doing. As a side note, I don’t know if this is necessarily a good thing because it allows people access to technology that can be used very unethically. Though in this case, we are using it to learn the basics and gather an intuition for Q-learning. The first thing we need to do is to create our learning environment:\nimport gym env = gym.make(\u0026#39;MountainCar-v0\u0026#39;) We can now define our network:\nfrom keras.models import Sequential from keras.layers import Dense, Activation, Flatten from keras.optimizers import Adam model = Sequential() model.add(Flatten(input_shape=(1,) + env.observation_space.shape)) model.add(Dense(128)) model.add(Activation(\u0026#39;relu\u0026#39;)) model.add(Dense(64)) model.add(Activation(\u0026#39;relu\u0026#39;)) model.add(Dense(32)) model.add(Activation(\u0026#39;relu\u0026#39;)) model.add(Dense(env.action_space.n)) model.add(Activation(\u0026#39;linear\u0026#39;)) First, notice that the first layer of the model is based on the observation space of the environment. This is telling the neural network what kind of input it should be expecting. At the tail end, you have a a layer that has the size of the action space. This means that for every action possible, the network will have an output node. Each output node represents an action that can be taken and the node with the highest output value will be used as an action for the given step. The rest of the network has important details that we are going to ignore. We only want to cover the basics and we will come back as we leave the top view and approach the bottom.\nNow that we have a network and an environment, we need it to learn. Better put, we need to have our network play a bunch of games and update itself to play even better. To do this, as mentioned, we are going to use Q-learning that has been implemented in Keras-RL.\nfrom rl.memory import SequentialMemory from rl.policy import BoltzmannQPolicy from rl.agents import DQNAgent dqn = DQNAgent( model=model, nb_actions=env.action_space.n, memory=SequentialMemory(limit=50000, window_length=1), nb_steps_warmup=10, target_model_update=1e-2, policy=BoltzmannQPolicy()) dqn.compile(Adam(lr=1e-3), metrics=[\u0026#39;mae\u0026#39;]) dqn.fit(env, nb_steps=150000, visualize=False, verbose=2) dqn.save_weights(\u0026#39;model.mdl\u0026#39;, overwrite=True) dqn.test(env, nb_episodes=5, visualize=True) In this block of code, there is a lot of things that, likely, will not make sense. For example, what is the BoltzmanQPolicy? At the moment, it is isn’t important so treat it like a black box. What is important in this block of code is that we can see the agent runs for 150,000 steps. Each game is composed of 200 steps which mean we give the agent 750 games to learn how to play the game. In my brief experiments with how many steps were necessary, this seemed to be the right amount. You’ll also notice that we have visualize while training set to false. This makes it so gym does not render every game which saves compute and will speed up our training time. After training, we save the model and run a test to see how it works.\nFigure 2: An example of the agent successfully reaching the target. If all went well, you’ll have a result similar to Figure 2. The source code of this project can be found on GitHub. You’ll notice I added command line arguments and some functions to make the code cleaner and easier to use when experimenting. In the next post, we are going to peel back the first layer and look into q-learning. We will either implement it and then go over the theory or do the opposite. I’m not sure yet which is best yet, so I’m not committing to either. In the meantime, I’d recommend playing with the variables to gain an intuition for reinforcement learning. Try to get a feel for why the agents in bigger examples like OpenAI’s Dota 2 bot or DeepMind’s AlphaZero required so many computers to learn how to play these more complicated games.\n","permalink":"http://localhost:1313/posts/q-learning-from-the-top/","summary":"\u003cp\u003eI want to go over Q-learning (a form of reinforcement learning) in this post. To start, we could go in two directions. We could explore at the bottom and look at the math behind neural networks and Q-learning. Or we could start at the top and see the end result. We are going to go with the latter.\u003c/p\u003e\n\u003cp\u003e\u003ccenter\u003e\n  \u003cfigure\u003e\n    \u003cimg src=\"/images/q-learning-top/env.jpg\" alt=\"\"\u003e\n    \u003csmall\u003eFigure 1: The mountain car environment.\u003c/small\u003e\n  \u003c/figure\u003e\n\u003c/center\u003e\u003c/p\u003e\n\u003cp\u003eTo do this we are going to need a few libraries and a testbed. To test, we are going to use \u003ca href=\"https://gym.openai.com/\"\u003eOpenAI’s Gym\u003c/a\u003e and use \u003ca href=\"https://gym.openai.com/envs/MountainCar-v0/\"\u003eMountainCar-V0\u003c/a\u003e. In this environment, proposed by Andrew Moore in his Ph.D. thesis, the car must reach the flag seen in figure 1. The car, though, does not have enough acceleration to achieve this by just going forward. Instead, it must go back and forward, steadily gaining enough speed to reach the goal. This is a problem that can be solved simply with a rule-based agent, however, reinforcement approaches can struggle with this. You’ll soon see that the amount of episodes it takes for q-learning to solve this is more than expected.\u003c/p\u003e","title":"Q Learning: Starting From the Top"},{"content":"One day at work, I walked by someone who was going through a large set of PDFs and for everyone he put a block box over the name field. He mentioned it would take him several hours to accomplish this extremely menial task. Naturally, I found myself attracted to the problem due to my love of automation. I decided then and there I would write a small script that he could use to redact large set of similarly formatted PDFs.\nEase of Use When going about this problem, I knew the most important part in the design would be ease of use. It couldn’t be a programmer’s tool with command line arguments and a readme file to boot. The most I could ask of this person was to open a terminal and type python redact.py. To address this problem there has to be GUI elements that allow the user to use familiar tools to define how and where the redaction takes place.\nTo address the problem of selecting pdfs, I decided to use TKinter, an easy to use tool that allows us to open a file explorer to select files or directories (this tool also does much more). With TKinter we have the first ease of use problem solved by making it so command line arguments won’t be needed to define where the program should find the pdfs, but we don’t have an easy way to choose where in a pdf a redaction should take place.\nIn my google searches I found many potential solutions, but none of them seemed reliable. One interesting approach was decoding pdfs into parsable fields, but past experience has shown me how unreliable parsing a pdf can be. I thought about allowing the user to define coordinates for where a black box should go to hide text. This was suboptimal, though, because it required multiple tests for the user to get the coordinates exactly right. After a bit more searching, I realized I could merge two pdfs. The first pdf would be the one we want to redact and the second would contain the black boxes that redacted the fields.\nWith both problems solved, in theory, I had an easy program flow:\nAsk the user for the directory where the pdfs are located Ask the user for the directory where all the redcated pfs should be located (you should never modify original files that are of any import) Ask the user for the pdf that only contains the redactions and is otherwise blank Redact the pdfs and put them in the outupt directory Merging a PDF Merging a pdf is pretty simple thanks to PyPDF2. We can use there PdfFileReader to read in pdfs from file paths. We get these paths with TKinter seen in the code at the bottom of the page. We will also need to create a new pdf with there PdfFileWriter that we can write to while merging two pdfs.\ndef redact(original_file_location, blocker_file_location): output = PdfFileWriter() original = PdfFileReader(file(original_file_location, \u0026#34;rb\u0026#34;)) blocker = PdfFileReader(file(blocker_file_location, \u0026#34;rb\u0026#34;)) if original.getNumPages() != blocker.getNumPages(): print \u0026#34;original has\u0026#34;, original.getNumPages(), \u0026#34;pages while the blocker has\u0026#34;, blocker.getNumPages(), \u0026#34;which is invalid.\u0026#34; return for page in xrange(original.getNumPages()): output_page = original.getPage(page) output_page.mergePage(blocker.getPage(page)) output.addPage(output_page) return output After that, we need to make sure the user hasn’t made any errors in selecting the redacting pdf or the directory. To do so, we check every pdf and the number of pages they have. If the page count does not match, then we cannot redact the pdf. An error is logged and the attempt to merge the two pdfs is dropped.\nWith the error check done, we simply loop through every page in the pdf and call the mergePage function. We add the output into the PdfFileWriter and we have successfully merged the two pdfs.\noutput = redact(os.path.join(input_directory, file), blocking_file) output_file = os.path.join(output_directory, file) with open(output_file, \u0026#39;wb\u0026#39;) as f: output.write(f) After calling the redact function, we can write the file to the output directory without any extra work having to be done thanks to the convenience of the PdfFileWriter.\nError and Conclusion At this point in the process, I was pretty stoked and ran the program and saw no errors. So I ran it on the real pdfs and showed off the results. The one I was helping, however, had other plans and opened the first redacted pdf with Adobe. He clicked on the black box that had redacted the participants name and, much to my horror, dragged the black box away to reveal the name of the participant. As mentioned before, I had kept the originals so there wasn’t any real issue with this, but it was disappointing.\noutput = redact(os.path.join(input_directory, file), blocking_file) output_file = os.path.join(output_directory, file) temp_output_file = output_file + \u0026#34;_temp\u0026#34; with open(temp_output_file, \u0026#39;wb\u0026#39;) as f: output.write(f) os.system(\u0026#34;pdf2ps \u0026#34; + temp_output_file + \u0026#34; - | \u0026#34; + \u0026#34;ps2pdf - \u0026#34; + output_file) os.remove(temp_output_file) It turns out that pdfs can have layers and when I merged the pdfs I simply wrote another layer on top of the original layer. My redaction was purely visual. I had to find a way to strip a pdf of it’s layers. I spent longer than I should have looking for a clean way to do this but couldn’t find anything. Eventually, I settled on writing a temp pdf in the output directory. After, I used a os.system to use PS2PDF which would remove the layers while keeping the original result. This last step drastically slowed down the redaction process, but after that it worked exactly as intended and saved a ton of time.\nfrom PyPDF2 import PdfFileWriter, PdfFileReader import Tkinter, tkFileDialog, tkMessageBox import pypdftk import os def redact(original_file_location, blocker_file_location): output = PdfFileWriter() original = PdfFileReader(file(original_file_location, \u0026#34;rb\u0026#34;)) blocker = PdfFileReader(file(blocker_file_location, \u0026#34;rb\u0026#34;)) if original.getNumPages() != blocker.getNumPages(): print \u0026#34;original has\u0026#34;, original.getNumPages(), \u0026#34;pages while the blocker has\u0026#34;, blocker.getNumPages(), \u0026#34;which is invalid.\u0026#34; return for page in xrange(original.getNumPages()): output_page = original.getPage(page) output_page.mergePage(blocker.getPage(page)) output.addPage(output_page) return output def redact_files_in_directory(input_directory, output_directory, blocking_file): files = os.listdir(input_directory) length = len(files) for i in range(length): file = files[i] if os.path.isfile(file): print file, \u0026#34;is not a file and cannot be converted\u0026#34; continue elif file.endswith(\u0026#39;.pdf\u0026#39;) == False: print file, \u0026#39;does not have the \u0026#34;.pdf\u0026#34; file extension and cannot be converted\u0026#39; continue output = redact(os.path.join(input_directory, file), blocking_file) output_file = os.path.join(output_directory, file) temp_output_file = output_file + \u0026#34;_temp\u0026#34; with open(temp_output_file, \u0026#39;wb\u0026#39;) as f: output.write(f) print \u0026#34;(\u0026#34; + str(i) + \u0026#34;/\u0026#34; + str(length - 1) + \u0026#34;): \u0026#34;, file os.system(\u0026#34;pdf2ps \u0026#34; + temp_output_file + \u0026#34; - | \u0026#34; + \u0026#34;ps2pdf - \u0026#34; + output_file) os.remove(temp_output_file) # only works on mac os.system(\u0026#39;say \u0026#34;your program has finished\u0026#34;\u0026#39;) def get_new_directory_path(window_title, window_message): tkMessageBox.showinfo(window_title, window_message) return tkFileDialog.askdirectory() def get_new_file_path(window_title, window_message): tkMessageBox.showinfo(window_title, window_message) return tkFileDialog.askopenfilename() if __name__ == \u0026#39;__main__\u0026#39;: input_directory = get_new_directory_path( \u0026#34;Input Directory\u0026#34;, \u0026#34;Select input directory path with files to be redacted.\u0026#34;) output_directory = get_new_directory_path( \u0026#34;Output Directory\u0026#34;, \u0026#34;Select output directory path.\u0026#34;) blocking_file = get_new_file_path( \u0026#34;Blocking File\u0026#34;, \u0026#34;Select pdf to block all pdf files in input directory \u0026#34; + input_directory) if blocking_file.endswith(\u0026#39;.pdf\u0026#39;) == False: print \u0026#34;blocking files must be a pdf file where the extension is \u0026#39;.pdf\u0026#39;\u0026#34; else: redact_files_in_directory(input_directory, output_directory, blocking_file) ","permalink":"http://localhost:1313/posts/redacting-pdfs/","summary":"\u003cp\u003eOne day at work, I walked by someone who was going through a large set of PDFs and for everyone he put a block box over the name field. He mentioned it would take him several hours to accomplish this extremely menial task. Naturally, I found myself attracted to the problem due to my love of automation. I decided then and there I would write a small script that he could use to redact large set of similarly formatted PDFs.\u003c/p\u003e","title":"Redacting PDFs"},{"content":"I came across a youtube video which showed a way to visualize fractal trees. I watched it while eating dinner and didn’t think much of it at the time. A week or two later, though, I had decided to a do a few more challenges for my challenges repository and this was at the top of the list. It is a fairly simple program that has a cool end result seen in figures one and four.\nFigure 1: Example tree visualization. Tools The aforementioned tutorial used p5.js and made it look pretty decent. However, using javascript isn’t something I would do for a personal project that is meant to be fun. As you may have guessed, I decided to use Python instead. The next step is to choose a tool to display the end result. My initial thought was to use matplotlib. However, the youtube tutorial also had animations. I wasn’t aware of animations being available in matplotlib at the time so I went in a different direction. Instead, I went with Pygame. I hadn’t used it before, but it I knew it was widely used in the Python community and I could find answers to any of my rudimentary questions online.\nOpening a Window Before we can start visualizing anything, we need a window that we can open and close without crashing. Luckily, there are a lot of sources that can be easily googled including Pygame’s documentation.\nimport pygame def main(): pygame.init() size = [800, 600] screen = pygame.display.set_mode(size) pygame.display.set_caption(\u0026#34;Fractal Tree\u0026#34;) done = False clock = pygame.time.Clock() while not done: clock.tick(10) for event in pygame.event.get(): if event.type == pygame.QUIT: done = True pygame.quit() if __name__ == \u0026#39;__main__\u0026#39;: main() The above code is the barebones necessary to get a black screen where nothing happens. It runs until the user closes the window. It works by calling the main function at the start. The main function initializes pygame on line 4 and then proceeds to define the size of the window. On line 9 we give the window a title. Line 12 is interesting because it\u0026rsquo;s purpose isn’t exactly clear on a first glance.\nLooking at the documentation, you’ll find, “By calling Clock.tick(40) once per frame, the program will never run at more than 40 frames per second.\u0026quot; This means we are telling pygame that it should run at most 10 frames per a second. Ten frames per a second is a very slow framerate for most games which aim for sixty, but for our black screen this is absolutely fine. After that we check for a pygame event where the user has quit and mark the boolean done as True. From there we tell pygame to quit and we have a black screen.\nCoordinate System and Drawing a Line It\u0026rsquo;s time to draw on the screen. To start we need to know how to draw a line. Luckily, pygame provides a very simple function pygame.draw.line which takes in the screen (line 6 of the code above), the color, the start position (x and y coordinates), the end position, and the width of the line. However, it’s very important to understand how the coordinate system works in the engine before going forward.\nFigure 2: Pygame coordinate system. A graph of how the coordinate system works can be seen in figure two and the source code can be found here. As you can see the top left of the screen corresponds to 0,0. The bottom right corresponds to the windows width and height.\nDrawing the Root of the Tree Now that we have an understanding of the coordinate system in Pygame we can move towards drawing a tree. First we need to draw the root line or base of the tree. To do this we need the start and the end positions. The start position is being supplied to us by the caller but for the first call it will need to be the width divided by two and the height of the screen (line 54 in the section below). The end position will have to be based on the direction of the line and the length.\nThe direction of the line can be defined with an angle. In our case, pi over two is a natural fit because we want the line to be vertical at the start. The length of our line can be any number we want but it will have to be negative to fit in the coordinate system of Pygame. This could also be accomplished by using a negative angle instead. Drawing the line can be seen in the code below:\ndef draw_line(screen, start_pos, line_length, current_angle): end_position = [ start_pos[0] + (line_length * math.cos(current_angle)), start_pos[1] + (line_length * math.sin(current_angle))] color = (255, 255, 255) # white line_width = 1 pygame.draw.line(screen, color, start_pos, end_position, line_width) Line 3 defines the x position where we use the start position plus the length of the line multiplied by the cosine of the angle. This is pretty common geometry so I’m going to skip explaining it. Line 4 does the same except for the y coordinate and uses sine. From there we define the color and line width and call the draw line function.\nDrawing the Tree Now that we can draw the root, the rest of this problem flows pretty naturally if we implement this recursively. Think of it like we are defining a new base of the tree that branches off the current base. If we change the name of the function draw_line to draw_fractal_tree we now have a clearer name. In the function it should call itself twice, since this is a fractal tree, with different directions. Before doing this, though, we need to make sure the recursion stops.\nWe could accomplish this by taking a max iterations approach. We could pass an integer on each call where we subtract it by one every time on the next call. Once the value is less than or equal to zero the function stops calling itself. This is a fine approach, but I believe the next approach, that is about to be described, is more natural fit for the problem.\nA more natural approach is to stop recursion based on the length of the line. Since drawing every branch of the tree with the same length would give a pretty weird looking result, we know the length of each branch should decrease on successive recursive calls. In addition, the tutorial also reduced the line length with every recursive call. To draw the tree we need to define how long the line segment on each call should be. Therefore, if we set a minimum line length we can know when the recursion should stop; this value is on line 14. Line 10 defines the maximum line length. In both cases, you’ll notice that the values are negative. As you’ll recall from the coordinates in figure two, the bottom of the screen is the height value, 600. Since we want to draw from the bottom of the screen to the top, we need to move towards 0 rather than away. Rather than creating a coordinate system on top of the existing one with conversions, I decided making the numbers negative would be simpler.\nLine 25 multiplies the current line length by a constant which should be between 0 and 1. This makes it so the value will approach 0 over time. Line 27 then checks to see if the line length is too small to continue. If not the function ends without an recursive calls. Else we call the function twice. You’ll notice that lines 28 and 29 are exactly the same except for a plus and a minus symbol. These are both using the delta_angle variable which is passed into the function.\nFigure 3: Example fractal tree where `delta_angle` is set to pi over two. The delta_angle variable is what defines how far direction changes for the next branch. If it was set to 0, then you would see only a straight line. If it was set to pi over two, ninety degrees, then you get two perpendicular lines seen in figure three.\nWith the tree implemented, all we have to do is make a few changes to our main function to see the results. The first change is in the for loop between lines 45 and 47 where the escape key now quits the window. First a check for a keydown is done and if that is true then a check for the escape key is done. Lastly, below the for loop, the screen is set to black and the tree is drawn. The flip call will update the entire display.\nfrom math import pi import pygame import math BLACK = ( 0, 0, 0) WHITE = (255, 255, 255) MIN_ANGLE = 0 MAX_ANGLE = pi LINE_LENGTH = -160 LINE_LENGTH_DIVISOR = 2.2/3.0 LINE_WIDTH = 1 MIN_LINE_LENGTH = -2 def draw_fractal_tree(screen, start_pos, line_length, delta_angle, current_angle): end_position = [ start_pos[0] + (line_length * math.cos(current_angle)), start_pos[1] + (line_length * math.sin(current_angle))] pygame.draw.line(screen, WHITE, start_pos, end_position, LINE_WIDTH) line_length *= LINE_LENGTH_DIVISOR if line_length \u0026lt; MIN_LINE_LENGTH: draw_fractal_tree(screen, end_position, line_length, delta_angle, current_angle + delta_angle) draw_fractal_tree(screen, end_position, line_length, delta_angle, current_angle - delta_angle)\tdef main(): pygame.init() size = [800, 600] screen = pygame.display.set_mode(size) pygame.display.set_caption(\u0026#34;Fractal Tree\u0026#34;) done = False clock = pygame.time.Clock() while not done: clock.tick(10) for event in pygame.event.get(): if event.type == pygame.QUIT: done = True if event.type == pygame.KEYDOWN: if event.key == pygame.K_ESCAPE: done = True # Clear the screen and set the screen background screen.fill(BLACK) # draw fractal tree at bottom middle of the screen with the first line # draw straight up at a 90 degree angle draw_fractal_tree(screen, [size[0]/2.0, size[1]], LINE_LENGTH, pi/5.0, pi/2.0) # Go ahead and update the screen with what we\u0026#39;ve drawn. # This MUST happen after all the other drawing commands. pygame.display.flip() pygame.quit() if __name__ == \u0026#39;__main__\u0026#39;: main() Animating the Tree What we have is pretty cool but with a few simple changes we can have the more impressive result seen in figure four. To accomplish this, we have to update the delta_angle every frame. In addition, we need to add something to handle when delta_angle has gone too far in one direction and start moving it back the other way.\nFigure 4: animated fractal tree. To update the delta_angle we can can use a simple lerp seen below. This will find the value between the minimum and maximum based on the percent. Therefore if the percent is 0 it will return the minimum. If the percent is 1 it will return maximum.\ndef lerp(minimum, maximum, percent): return minimum + percent * (maximum - minimum) The other piece needed is a similarly simple function. The variable current_step is the percentage between 0 and 1 that is used in the lerp function. increment is how much the step should increase every call and can be configured. direction is either -1 or 1 and makes it so the increment is either positive or negative depending on which way the tree is moving. The rest just makes it so percent stays between 0 and 1 and moves between the two over time.\ndef update_step(current_step, increment, direction): new_step = current_step + (increment * direction) if new_step \u0026lt;= 0: direction = 1 new_step = 0 elif new_step \u0026gt;= 1: direction = -1 new_step = 1 return new_step, direction With that added we can update the main function to have two variables current_step and direction. The lerp function is used for the delta_angle in the draw_fractal_tree call. After drawing, we call the update_step which updates the step and direction for the next frame.\nThe source code of the project can be found here. You’ll notice I separated everything out a bit and added a config file to make it easier to modify behavior.\ndef main(): # Initialize the game engine pygame.init() # Set the height and width of the screen size = [800, 600] screen = pygame.display.set_mode(size) pygame.display.set_caption(\u0026#34;Fractal Tree\u0026#34;) #Loop until the user clicks the close button. done = False clock = pygame.time.Clock() current_step = 0 direction = 1 while not done: # This limits the while loop to a max of 10 times per second. # Leave this out and we will use all CPU we can. clock.tick(10) for event in pygame.event.get(): if event.type == pygame.QUIT: done = True if event.type == pygame.KEYDOWN: if event.key == pygame.K_ESCAPE: done = True # Clear the screen and set the screen background screen.fill(Config.BLACK) # draw fractal tree at bottom middle of the screen with the first line # draw straight up at a 90 degree angle delta_angle = lerp(Config.MIN_ANGLE, Config.MAX_ANGLE, current_step) draw_fractal_tree(pygame, screen, [size[0]/2.0, size[1]], Config.LINE_LENGTH, delta_angle, pi/2.0) # Go ahead and update the screen with what we\u0026#39;ve drawn. # This MUST happen after all the other drawing commands. pygame.display.flip() current_step, direction = update_step(current_step, Config.STEP, direction) ","permalink":"http://localhost:1313/posts/fractal-tree/","summary":"\u003cp\u003eI came across a \u003ca href=\"https://www.youtube.com/watch?v=0jjeOYMjmDU\"\u003eyoutube video\u003c/a\u003e which showed a way to visualize fractal trees. I watched it while eating dinner and didn’t think much of it at the time. A week or two later, though, I had decided to a do a few more challenges for my \u003ca href=\"https://github.com/bi3mer/challenges\"\u003echallenges repository\u003c/a\u003e and this was at the top of the list. It is a fairly simple program that has a cool end result seen in figures one and four.\u003c/p\u003e","title":"Visualizing Fractal Trees"},{"content":"A Quick Note I ended up getting pretty sick and I was out of commission for about two months. The good news is that I’m now in perfectly good health. The bad news is that it kind of destroyed my hopes of building a decent submission for GDMC. The competition ends in about thirteen days which is not enough time to come up with a submission I would be proud of. In addition, my 40+ hours at the Brain Game Center, where I work, every week is the very large nail in the coffin. Regardless, I plan on continuing to work on this problem until I have something cool I can show off.\nCounting Materials In a Selection The last post featured basic drawing methods to be able to write changes to the map. In this post, I’m attempting to get a better understanding of the level data structure we are given. WIth that in mind, the first thing I want to do is go over how to inspect a block in MCEdit.\nMy initial attempt at this was a failure because I assumed getting a block would follow a similar naming convention to the setBlockAt function. Much to my surprise, this was not the case. Searching through the the code showed that the correct function is actually blockAt. With that unfortunate mistake behind, it was super easy to modify my fill selection code from the last post.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Selection Material Counter\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def perform(level, box, options): final_x = box.origin.x + box.size.x final_y = box.origin.y + box.size.y final_z = box.origin.z + box.size.z materials = {} for x in range(min(box.origin.x, final_x), max(box.origin.x, final_x)): for y in range(min(box.origin.y, final_y), max(box.origin.y, final_y)): for z in range(min(box.origin.z, final_z), max(box.origin.z, final_z)): material = level.blockAt(x,y,z) if material not in materials: materials[material] = 0 materials[material] += 1 print \u0026#34;Material Counts\u0026#34; for key in materials: print \u0026#34;\\t\u0026#34; + str(key) + \u0026#34;: \u0026#34; + str(materials[key]) I used a dictionary with a key to the material and a value of the count. Each material checks to see if it exists in the dictionary and if not it adds itself with a value of 0. After this check, the dictionary value for the key is incremented. After looping through the selection, a loop is used to print out all the values. The output after running on a random selection I made can be seen below.\nMaterial Counts 0: 2361 1: 80 2: 728 3: 917 37: 7 12: 12 17: 93 18: 726 31: 44 Rewriting Every Block Except Empty From the last post we already know how to fill in a space with a material and even make it modifiable from the the UI. We can take the exact same code and add an if statement at the end of the three for loops to check if the block in question is empty and does not have an ID of 0. If it doesn\u0026rsquo;t we can overwrite it, else we can continue onwards.\nFigure 1: Sample where all non-empty blocks are turned into coal. As a note, in mcedit there is a file minecraft.json which defines every block and it’s data. Unfortunately, there isn’t one for empty space. However, looking at the the code in materials.py there is a hardcoded value for air that can be used.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Replace All Except Air\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) def fill_box(level, origin, size, material): final_x = origin.x + size.x final_y = origin.y + size.y final_z = origin.z + size.z for x in range(min(origin.x, final_x), max(origin.x, final_x)): for y in range(min(origin.y, final_y), max(origin.y, final_y)): for z in range(min(origin.z, final_z), max(origin.z, final_z)): if level.blockAt(x,y,z) != 0: draw_block(level, x, y, z, material) def perform(level, box, options): fill_box(level, box.origin, box.size, options[\u0026#34;Material\u0026#34;]) Nuke Now we can focus on recreating what was done by Christoph Salge in his tweet also seen in figure two. It replaces the top layer of the world with obsidian and tree blocks with coal. In addition, I’ve decided to replace water with lava. All of this is pretty easy except for replacing the top layer of the world. So we are going to break this problem down into two parts. First, we are going to replace the top layer of the world with any material. After that, we are going to combine the result of the first part with the extra replacements to recreate the entire filter.\nFigure 2: Christoph Salge’s filter in action from his tweet. Replacing the Top Layer Up until now every for loop that we have used has been looping through every x, then every y, and then every z to look through the map. This works pretty well but now we have to change it. Mcedit uses a coordinate system where the y coordinate is representative of the height. Therefore, we are going to change our loop to go x, z, and then y. In addition, instead of going from the smallest y to the largest y, we are now going to do the opposite. This means that for every x and z coordinate we will loop from the top of the users selection to the bottom.\nFigure 3: Replacing the to layer with coal. From there, we can loop through the y coordinates and stop once we find a material that isn’t air. The effect can be seen in figure three and the code is directly below.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Replace Top Layer\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) def fill_box(level, origin, size, material): final_x = origin.x + size.x final_y = origin.y + size.y final_z = origin.z + size.z for x in range(min(origin.x, final_x), max(origin.x, final_x)): for z in range(min(origin.z, final_z), max(origin.z, final_z)): # loop from the top until we reach a material that is not empty for y in reversed(range(min(origin.y, final_y), max(origin.y, final_y))): if level.blockAt(x,y,z) != alphaMaterials.Air.ID: draw_block(level, x, y, z, material) break def perform(level, box, options): fill_box(level, box.origin, box.size, options[\u0026#34;Material\u0026#34;]) Replacing the Top Layer and All Other Materials We can break this problem into 3 parts to get the effect seen in figure four:\nReplace the top layer with obsidian Replace all water with lava Replace all trees with coal and remove the leaves Figure 4: Nuke effect in action. The first effect is now easy, we use the code from the section above and give it the material of Obsidian. The second effect is also easy, we use our replace all function and change it to only change the value to lava if the given block is water. The only thing to note is that we have to use the materials ID instead of just the material. Lastly, we do the same thing as the second part but also check for leaves. With wood we replace it with coal and with leaves we replace it with air. It is important to note that the the replace top layer function must be called last or you will end up with obsidian blocks where leaves used to be. The code below directly represents this line of thought but you’ll probably notice it is fairly inefficient.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from pymclevel.box import Vector from mcplatform import * inputs = ( (\u0026#34;Nuke\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) # We do this last, so we can assume leaves have been destroyed and # wood has been changed to coal def fill_top_layer_with_obsidian(level, origin, size): for x in range(min(origin.x, size.x), max(origin.x, size.x)): for z in range(min(origin.z, size.z), max(origin.z, size.z)): # loop from the top until we reach a material that is not empty for y in reversed(range(min(origin.y, size.y), max(origin.y, size.y))): block = level.blockAt(x,y,z) if block != alphaMaterials.Air.ID and \\ block != alphaMaterials.CoalBlock.ID and \\ block != alphaMaterials.Lava.ID: draw_block(level, x, y, z, alphaMaterials.Obsidian) break def replace_all_water_with_lava(level, origin, size): for x in range(min(origin.x, size.x), max(origin.x, size.x)): for y in range(min(origin.y, size.y), max(origin.y, size.y)): for z in range(min(origin.z, size.z), max(origin.z, size.z)): block = level.blockAt(x,y,z) if block == alphaMaterials.Water.ID or block == alphaMaterials.WaterActive.ID: draw_block(level, x, y, z, alphaMaterials.Lava) def replace_all_trees_with_coal(level, origin, size): for x in range(min(origin.x, size.x), max(origin.x, size.x)): for y in range(min(origin.y, size.y), max(origin.y, size.y)): for z in range(min(origin.z, size.z), max(origin.z, size.z)): block = level.blockAt(x,y,z) if block == alphaMaterials.Wood.ID: draw_block(level, x, y, z, alphaMaterials.CoalBlock) elif block == alphaMaterials.Leaves.ID: draw_block(level, x, y, z, alphaMaterials.Air) def perform(level, box, options): size = Vector(box.origin.x + box.size.x, box.origin.y + box.size.y, box.origin.z + box.size.z) replace_all_water_with_lava(level, box.origin, size) replace_all_trees_with_coal(level, box.origin, size) fill_top_layer_with_obsidian(level, box.origin, size) The above code is inefficient because it does the same three loops three times in three different functions. It was convenient to write the program this way the first time because it was clear and helped organize our thoughts. However, now that we have a working version it is worthwhile to go back and figure out a way to combine all three loops.\nThis means copying the inner loops and pasting them into one for loop, however there is some conflict with the replace top layer loop. A first step could be to to write two for loops for the y coordinate at the end: one for the water and trees and the other for the top layer.\ndef nuke(level, origin, size): for x in range(min(origin.x, size.x), max(origin.x, size.x)): for z in range(min(origin.z, size.z), max(origin.z, size.z)): for y in range(min(origin.y, size.y), max(origin.y, size.y)): block = level.blockAt(x,y,z) if block == alphaMaterials.Water.ID or block == alphaMaterials.WaterActive.ID: draw_block(level, x, y, z, alphaMaterials.Lava) elif block == alphaMaterials.Wood.ID: draw_block(level, x, y, z, alphaMaterials.CoalBlock) elif block == alphaMaterials.Leaves.ID: draw_block(level, x, y, z, alphaMaterials.Air) # loop from the top until we reach a material that is not empty for y in reversed(range(min(origin.y, size.y), max(origin.y, size.y))): block = level.blockAt(x,y,z) if block != alphaMaterials.Air.ID and \\ block != alphaMaterials.CoalBlock.ID and \\ block != alphaMaterials.Lava.ID: draw_block(level, x, y, z, alphaMaterials.Obsidian) break This is a good first step, however, we can improve it by making it work in one loop rather than two. The only step is to create a set of if, else if statements where the top layer statement is last. You may have concerns about the break ruining the filter, however, this break actually makes it so we do less work and still get the same effect. I’m leaving it as a thought experiment for anyone who wants to figure out how this works.\ndef nuke(level, origin, size): for x in range(min(origin.x, size.x), max(origin.x, size.x)): for z in range(min(origin.z, size.z), max(origin.z, size.z)): # loop from the top until we reach a material that is not empty for y in reversed(range(min(origin.y, size.y), max(origin.y, size.y))): block = level.blockAt(x,y,z) if block == alphaMaterials.Water.ID or block == alphaMaterials.WaterActive.ID: draw_block(level, x, y, z, alphaMaterials.Lava) elif block == alphaMaterials.Wood.ID: draw_block(level, x, y, z, alphaMaterials.CoalBlock) elif block == alphaMaterials.Leaves.ID: draw_block(level, x, y, z, alphaMaterials.Air) elif block != alphaMaterials.Air.ID and \\ block != alphaMaterials.CoalBlock.ID and \\ block != alphaMaterials.Lava.ID: draw_block(level, x, y, z, alphaMaterials.Obsidian) break ","permalink":"http://localhost:1313/posts/gdmc2/","summary":"\u003ch1 id=\"a-quick-note\"\u003eA Quick Note\u003c/h1\u003e\n\u003cp\u003eI ended up getting pretty sick and I was out of commission for about two months. The good news is that I’m now in perfectly good health. The bad news is that it kind of destroyed my hopes of building a decent submission for GDMC. The competition ends in about thirteen days which is not enough time to come up with a submission I would be proud of. In addition, my 40+ hours at the \u003ca href=\"https://braingamecenter.ucr.edu/\"\u003eBrain Game Center\u003c/a\u003e, where I work, every week is the very large nail in the coffin. Regardless, I plan on continuing to work on this problem until I have something cool I can show off.\u003c/p\u003e","title":"Generative Design in Mineraft: Nuking the Ground"},{"content":"If you’ve read my previous posts, then you know I love python. Regardless, it has been a goal of mine to be proficient in c++. I’m not exactly sure why I’m fascinated with this language that I have no uses cases for, but I think it stems from my love of video games. C++ is used extensively by my favorite company, Blizzard Entertainment, and sees a wide range of use across the industry. In addition, it also is apart of a field that is of particular interest for me, AI. For example, tensorflow is implemented in c++.\nWith my interest in c++ in mind, I decided to write a few sorting algorithms as a way to practice using the language without doing anything too extensive. What resulted was a series of dull challenges which really tells you nothing about me as a programmer and if I can do anything. However, I recalled watching these youtube videos from when I was freshman first learning the algorithms and decided visualizing my implementations may be a way to add some spice to what was otherwise a very dull set of implementations.\nQuick Sort Implemented in c++ int partition(int* a, int low, int high) { int lowIndex = low - 1; int pivot = a[high]; for(int i = low; i \u0026lt; high; ++i) { if(a[i] \u0026lt;= pivot) { ++lowIndex; std::swap(a[lowIndex], a[i]); } } ++lowIndex; std::swap(a[lowIndex], a[high]); return lowIndex; } void quickSortImplemented(int* a, int low, int high) { if(low \u0026lt; high) { int pi = partition(a, low, high); quickSort(a, low, pi - 1); quickSort(a, pi + 1, high); } } void quickSort(int* a, int length) { quickSortImplemented(a, 0, length - 1); } Installing Glut on Ubuntu Glut is a way for c++ to be able to talk to OpenGL and draw things. For installing glut I found a helpful article which gave me the installation commands I needed to run:\nsudo apt-get install mesa-common-dev sudo apt-get install freeglut3-dev They also provide a sample program that will draw a white square on a black background.\n#include \u0026#34;GL/freeglut.h\u0026#34; #include \u0026#34;GL/gl.h\u0026#34; /* display function - code from: http://fly.cc.fer.hr/~unreal/theredbook/chapter01.html This is the actual usage of the OpenGL library. The following code is the same for any platform */ void renderFunction() { glClearColor(0.0, 0.0, 0.0, 0.0); glClear(GL_COLOR_BUFFER_BIT); glColor3f(1.0, 1.0, 1.0); glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0); glBegin(GL_POLYGON); glVertex2f(-0.5, -0.5); glVertex2f(-0.5, 0.5); glVertex2f(0.5, 0.5); glVertex2f(0.5, -0.5); glEnd(); glFlush(); } /* Main method - main entry point of application the freeglut library does the window creation work for us, regardless of the platform. */ int main(int argc, char** argv) { glutInit(\u0026amp;argc, argv); glutInitDisplayMode(GLUT_SINGLE); glutInitWindowSize(500,500); glutInitWindowPosition(100,100); glutCreateWindow(\u0026#34;OpenGL - First window demo\u0026#34;); glutDisplayFunc(renderFunction); glutMainLoop(); return 0; } With our packages and program we can now test to see if it will run. To test, input the following in your terminal. Please note, I assume you’ve named this file main.cpp in the commands below.\ng++ main.cpp -lGL -lGLU -lglut ./a.out Drawing in OpenGL with Glut Now that we can draw things, we need to understand how exactly we are drawing. The first thing to notice in the sample program above, is how it draws the square where every vertex has either -0.5 or 0.5 for the x and y axis.\nRepresentation of square generated in sample code for OpenGL As you can see in figure one, source code here, the blue square is the square we see when running our c++ code. The black lines represent the axis and ultimately show us how we are expected to draw with this framework. -1 to 1 are the boundaries on both the x and y axis. So the vertex (-1,-1) would be the bottom left of the screen and (1,1) would be the top right.\nDrawing a Frame A frame for us is a visual representation of the array we are sorting and the progress. Therefore, before we can starting writing code we have to define the array we want to visualize. Luckily, this is fairly simple because our goal isn’t to write something super generic. Our one and only goal is to write something that visualizes the sort. WIth that in mind let’s assume an array is a set of integers ordered from 0 to n, where n is some arbitrary length greater than 0.\nint* arr = (int*) malloc(sizeof(int) * length); for(int i = 0; i \u0026lt; length; ++i) { arr[i] = i; } Please note, I’m aware that the malloc isn’t necessary but it will come into play later so please just bear with me. With our array now defined, we need a render function that will be able to draw rectangles for each and every element of the array inside of our window. These rectangles need to scale based on the size of the array.\nvoid renderFunction() { glClearColor(0.0, 0.0, 0.0, 0.0); glClear(GL_COLOR_BUFFER_BIT); glColor3f(1.0, 1.0, 1.0); glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0); float l = (float) length; float widthAdder = 1/l; for(int i = 0; i \u0026lt; length; ++i) { glBegin(GL_POLYGON); // + 1 so value of 0 has height of 1 float arrayIndexHeightRatio = 2*(arr[i] + 1)/l; float widthIndexAdder = 2*i/l; float leftX = -1 + widthIndexAdder; float rightX = leftX + widthAdder; float bottomY = -1; float topY = bottomY + arrayIndexHeightRatio; // bottom left glColor4f(1,0,0,0); glVertex2f(leftX, bottomY); // bottom right glColor4f(0,1,0,0); glVertex2f(rightX, bottomY); // top right glColor4f(0,0,1,0); glVertex2f(rightX, topY); // top left glColor4f(0,0,0,1); glVertex2f(leftX, topY); glEnd(); } glFlush(); } Now there is a decent bit going on here, so let’s break it down. The most important thing to notice is that I’m using variables arr and length without ever having declared them or passed them into the function. The unfortunate reality here is that there is no way, that I could find, to pass a variable into the render function. Now I imagine a class would resolve this, but I used a global because I knew this code would only be used once. If I thought, for even a second, that I would use it again then I would have attempted the class approach or anything to avoid having these horrible globals.\nThe first set of commands is clearing the screen so we can draw on it without drawing over anything else. After that we convert the length to a float so we can divide by it without worrying about integer rounding. We then create this variable called widthAdder which is how long, widthwise, a rectangle will be. Also, please note, you could do 2/l instead which would cause the rectangles to touch as seen in figure two.\n1/l 2/l We now begin looping over every element of the array to draw the rectangle that represents the given element. We use the element’s index to determine where it is located along the x axis and the actual value to determine the height. To start we call a function glBegin with an enumeration to a polygon. With every glBegin call there will always be a glEnd call that you see at the end of the loop. After the begin call we create a variable which represents the height of the index. We calculate this by taking the value and adding one, this ensures the zero value will be shown, and multiplying the result by two. This multiplication allows us to use the entire screen of negative one to one. We then divide by the length of the array to properly scale the result. You’ll notice that the +1 we used for making 0 show on the screen also set the scaling to a proper factor. The other way to resolve this would have been to divide by the length subtracted by 1.\nThe next variable allows us to find the starting x coordinate before subtracting by one. We take the index of the element and divide by the length. From there we multiply it by two. Once we subtract by one we will have the starting left x coordinate.\nWith this math completed, all we have to do is finish up our variable definitions for the four corners of the rectangle and draw out the vertices. You’ll notice that I added colors to the vertices as well so the resulting graphs would be prettier. The results of this can be seen in Figure 2 after randomizing the array for an array of size 500.\nFigure 2: Sample graph generated for a randomized array Visualizing the Sort Now we want to redraw the entire screen after every single swap (an optimization for this would be to only redraw the areas of the screen for the two rectangles that are swapped). The easiest way to do this is to write our own version of swap that will still use the std::swap function, but also call the render function.\nvoid swap(int index1, int index2) { std::swap(arr[index1], arr[index2]); renderFunction(); usleep(delay); } You’ll notice that I take advantage of the horrible global and actually don’t pass it in. In addition, I’ve added an extra line usleep(delay) which pauses the execution for however many milliseconds. This makes it so we can actually see the sort happening. This function call isn’t necessarily ideal for all operating systems and using boost instead would be optimal. In addition, you’ll notice that delay is also undefined and must therefore be a global. This is the third and second to last global (length is the second).\nWith swapping implemented, we now need a generic way of passing our sorting algorithm to the visualizer. Luckily, c++ gives us an easy way to pass functions.\nint setUpGlutAndArray(int argc, char** argv, void (*sortingAlgorithm)(int*, int)) { sort = sortingAlgorithm; arr = (int*) malloc(sizeof(int) * length); for(int i = 0; i \u0026lt; length; ++i) { arr[i] = i; } randomizeArray(arr, length); glutInit(\u0026amp;argc, argv); glutInitDisplayMode(GLUT_SINGLE); glutInitWindowSize(length,length); glutInitWindowPosition(100,100); glutCreateWindow(\u0026#34;Sort Visualization\u0026#34;); glutDisplayFunc(renderFunction); glutKeyboardFunc(keyboardEvent); glutMainLoop(); } This function sets our fourth and final global, the swapping algorithm. After that, it does the exact same things from the original main function we have above, except, there is now a keyboard function and a randomize array function.\nThe keyboard function is called on keyboard events and takes in a few arguments. In our case we use this event to handle the escape key, 27, and s key, 115. When the escape key is pressed we quit out. When the s key is pressed, we start the sort.\nvoid keyboardEvent(unsigned char c, int x, int y) { if(c == 27) { // exit on escape key pressed exit(0); free(arr); } else if(c == 115) { // start on `s` key pressed sort(arr, length); } } What we now have is a complete program and all we have to do is set up our main function. Say we wanted to see how quicksort looked. Then we could create a main function underneath our quicksort code from above; please note that the sorting algorithm will have to use the new swap function. Sample source code can be found here.\nint main(int argc, char* argv[]) { srand(time(NULL)); delay = 1500; length = 500; setUpGlutAndArray(argc, argv, quicksort); free(arr); return 0; } And when running and after pressing s, we would get the gif seen in Figure 3.\nFigure 3: Example gif produced from running quicksort. Conclusion If I wanted to spend more time on this then the first thing I would do is remove all four of those horrible globals. However, besides that one element I’m pretty happy with the result. I think the visualization came out looking pretty good and it was shocking to see just how much faster quicksort really is then something like bubble sort. In addition, it was also just good experience to work in OpenGL and familiarize myself with tools that are a little outside of my comfort zone.\n","permalink":"http://localhost:1313/posts/visualizing-sorting-algorithms-with-opengl/","summary":"\u003cp\u003eIf you’ve read my previous posts, then you know I love python. Regardless, it has been a goal of mine to be proficient in c++. I’m not exactly sure why I’m fascinated with this language that I have no uses cases for, but I think it stems from my love of video games. C++ is used extensively by my favorite company, Blizzard Entertainment, and sees a wide range of use across the industry. In addition, it also is apart of a field that is of particular interest for me, AI. For example, \u003ca href=\"https://github.com/tensorflow/tensorflow\"\u003etensorflow\u003c/a\u003e is implemented in c++.\u003c/p\u003e","title":"Visualizing Sorting Algorithms with OpenGL"},{"content":"Source Control and GitHub GitHub is an awesome website that allows you to have unlimited repositories, for free, that are backed up with git on a remote server. In addition, it provides you with helpful tools like issues that allow you to keep track of bugs, features, and anything else you want. It is not the end all be all of source control and has pros and cons that should be considered before being used.\nFor our use case, github is the perfect option because it is a free service that allows anyone to see our code easily. Other services, are either going to cost money or make it difficult to distribute the code. With that said, we are using version control for more than just visibility. For every project, working with version control is mandatory. If you plan on working with a group, then it provides a single workspace where you don’t have to manage a set of files and combining them. It allows you to revert back if you’ve made a huge mistake. It allows you to experiment on separate branches while not breaking the main branch.\nThe list that I provided is drastically shorter than the whole, but feel free to search google for more examples of why you should use source control. Regardless, please do not make the mistake of thinking that version control is only for group projects. It is for all projects.\nAdding Python as the `.gitignore` file With that said we can now create our repository. To create a github account, go to their create an account page and sign up (it’s free). From there, follow their instructions on creating a repository and make sure to set the dropdown menu “Add .gitignore” to “Python” as seen in figure one. I named my repository UnBlockMeSolver, but any name that is descriptive and follows these guidelines is fine (make sure to avoid special characters like #, %, :, etc.).\nMatrix Board Formats For me, defining a program that is configurable is of the utmost importance. I personally believe it leads to better design and creates more robust programs. When making games, I want to make it so designers can easily change behavior without having to come to me to get the changes in. Usually this means exposing some kind of file that they can modify. The first step in our game’s configurability is to create a file format for defining a board.\nLooking at the requirements we defined in the last post, we know that every piece on the board has a unique identifier. This means '1', 'abc', and 'b' are technically viable piece names. However, I personally would like to exclude the id ‘abc’ if possible. If we restrict an id to having at most one character than we lose some flexibility but have an easier implementation. The flexibility we lose is an, almost, unlimited number of unique identifiers. Instead we will only have approximately 36 ids (26 letters in the alphabet plus 10 numbers of zero to nine). With that said, we technically have more with symbols and special characters but it would be an inconvenience for designers to type out. We can have even more if we include capitals and lower case characters.\nOnly having around 36 items on a board really isn’t going to hinder us. Our initial goal is to work with boards that are 6x6 which is the standard for both Rush Hour and Unblock Me. It is impossible, therefore, for us to have greater than 18 pieces on the board (18 2x1 pieces would perfectly fill the board). Since we know 36 unique identifiers will not hinder us, we now have to ask whether we can see cases in the future where this will change. I personally can see a case where I may want to test on a bigger board, however, I see that future as very unlikely. So, instead I’m going to update the first requirement to be, “The board will be represented by a two dimensional matrix that contains unique character identifiers for each block.\u0026quot;\nWith that update completed, we now to handle the second and third requirements:\nThe board will have a unique identifier which represents the goal. The board will have a unique identifier which represents the red block or main block. We need to define constants for the goal and the the main block. But that is actually incomplete. We also need to define a constant for empty space. In addition, I’ve decided to add some extra complexity to our version by allowing there to be walls. These walls will be unable to move and take up one or more spots.\nwall = \u0026#34;|\u0026#34; goal = \u0026#34;$\u0026#34; empty = \u0026#34;0\u0026#34; playerPiece = \u0026#34;*\u0026#34; These constants could be random characters, but since they will be exposed to designers it is important to make them as easy to understand as possible.\nSample Unblock Me board The last step is to produce a sample map that we can use when testing our parser. To do so, we can copy the map seen in figure two into our format:\n010000 010020 **3020$ 003000 400555 400000 What you probably notice is that our goal is sticking out. This complicates are implementation because we will have unequal dimensions. This now puts us in a situation where can either modify a requirement, again, or update the definition of the matrix to hide this issue.\nUpdating the requirement would likely mean removing the goal from the matrix. Instead we would create a required field where we defined the x and y coordinates of the goal.\n(6,2) 010000 010020 **3020 003000 400555 400000 I personally don’t like this option because it complicates our parsing and sets up weird edge cases where we aren’t technically worried about going out of bounds of the matrix to find the solution for the game.\nAlternatively, we could simply surround the whole matrix with walls. This makes it so we can still define a goal wherever we want and now have a full matrix where special cases are not needed to be handled. With that update we would now have the following matrix in a file:\n|||||||| |010000| |010020| |**3020$ |003000| |400555| |400000| |||||||| Technically, the walls on top can be avoided but I’m imagining cases in the future where we use these walls to help the GUI properly render the board. It may not come into fruition, but it won’t hurt.\nUpdate (2024/11/21) Part of the process of updating my website has been converting converting all my old posts to new ones. Coming across this one was odd because I know I worked a lot on the codebase. If you look at the repository, you\u0026rsquo;ll see that I implemented the game, a server with Heroku working with documentation, and a solver. I was working on puzzle generation, and I had some work going on improving the solver with heuristics. In short, I had a lot of stuff to write about. However, I didn\u0026rsquo;t and I don\u0026rsquo;t remember why. So, for anyone who enjoyed these two posts, apologies that I didn\u0026rsquo;t continue.\n","permalink":"http://localhost:1313/posts/making-rush-hour-2/","summary":"\u003ch1 id=\"source-control-and-github\"\u003eSource Control and GitHub\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/\"\u003eGitHub\u003c/a\u003e is an awesome website that allows you to have unlimited repositories, for free, that are backed up with \u003ca href=\"https://git-scm.com/\"\u003egit\u003c/a\u003e on a remote server. In addition, it provides you with helpful tools like \u003ca href=\"https://docs.github.com/en/issues/tracking-your-work-with-issues/about-issues\"\u003eissues\u003c/a\u003e that allow you to keep track of bugs, features, and anything else you want. It is not the end all be all of \u003ca href=\"https://aws.amazon.com/devops/source-control/\"\u003esource control\u003c/a\u003e and has \u003ca href=\"https://www.timedoctor.com/blog/git-mecurial-and-cvs-comparison-of-svn-software/\"\u003epros and cons that should be considered\u003c/a\u003e before being used.\u003c/p\u003e","title":"Making Rush Hour: Github and Matrix Formats"},{"content":"This is the first in a series of posts where I discuss implementing a version of Unblock Me and Rush Hour; sample screen shots can be seen in figure one. For the implementation, I’ve decided to use Python 2.7, however, you should be able to follow along with any language. My hope is that each of these posts will be more than just a copy and paste tutorial. To facilitate this, I will be taking deep dives into design decisions, test-driven design, common game AI architecture, general software structure, requirements gathering, servers, and more.\nWhy Python? Choosing a language for a project is one of the most important decisions that you’ll have to make. It will define how you approach problems, what problems you feel comfortable solving, and even how fast your code will execute. For these reasons, and more, it is imperative to choose a language for a better reason than, “It’s my favorite programming language.”\nIronically, one of the main reasons I decided to use python for this project is that it is favorite language. My original goal was to show prospective employers an example project that goes beyond the usual, “I stopped once I got it working.” I wanted to create something that I would feel comfortable showing off not only for the functionality but also the code quality. WIth that in mind, I decided to use python because it would allow me to completely focus on the design and code quality thanks to my level of familiarity with the language.\nIn addition, I knew python would be the best bet in the long run because after implementing the game I intend to look into procedural generation of valid boards and machine learning techniques to generate a valid heuristic for A* pathfinding. Both of these goals are well suited for python and the bonus isomorphism makes a life a tad bit easier in the future.\nRequirements It may seem like common sense, but the most important part in programming is knowing exactly what the end goal is for the project. If you know the end goal, you can quickly program to those exact specifications without worry that something will change midway through. Unfortunately, the reality of software development is that things will change and the program will have to change with them. Therefore, it is necessary to develop fully knowing that code you’ve written yesterday will change to accomodate a new feature or idea. The best way to handle these changes is to design with flexibility in mind. Usually this means expecting the changes before they have been requested.\nThis can lead some to make the program so flexible that becomes unreasonable and out of scope. One particular moment of mine that stands as is when I decided to make a simple chess game. At the start I was programming with the obvious constraint of the board being in two dimensions. But I had a thought that it may be cool to make the game configurable so someone could play in two dimensions or higher. What resulted was a series of headaches and unnecessary pain for a feature that would never be used. Knowing the right kind of flexibility to add when developing software is key and something that comes with time.\nIn our case, we won’t have to worry about a project manager changing requirements midway through the project but we still have to worry about getting a bright idea that can change everything. Therefore, before even writing our first line of code we need to develop a set of requirements that will be true throughout the project. These requirements will define the core of the game.\nThe board will be represented by a two dimensional matrix that contains unique identifiers for each block. The board will have a unique identifier which represents the goal. The board will have a unique identifier which represents the red block or main block. A block that is longer lengthwise than heightwise can only be moved horizontally one space or more. A block that is longer heightwise than lengthwise can only be moved vertically one space or more. A block that is equal in length and height cannot exist. A block can not be moved through another block. Only the main block can take the spot of the goal on the board. The game will end when the player has managed to slide the main block into the goal. This is not a complete set of requirements, for more on this topic you can view BelitSoft\u0026rsquo;s standard, but it does serve as a baseline for future development. Nothing we develop will go against these requirements. More rigorous requirements building in a professional environment is essential because they force everyone to be on the same page for what is going to be built.\nStructuring the Project With our requirements complete, we can now work on defining how we want everything to be structured. The first decision is to figure out a proper file structure knowing we will have one main project with multiple, dependent, side projects. Therefore, a simple flat structure of python files being in the root directory is far too simple for our use case. We want to make everything clear and streamlined so users can easily find what they want.\nThe two popular solutions for this problem are to create separate repositories with submodules to the required repositories or to use a a monolithic repository. The first solution isn’t ideal because it sets up cases where we can make changes to one repository that will force multiple dependent repositories to update. This issue becomes exacerbated when repositories are thrown of sync due to simply forgetting to update. Meaning, the main weakness of this approach is that we have to be hyper vigilant when making changes to any repository. The second option means we will have folders at the root for each part of the project we’ll want to build. This means linking them up may not be ideal. For example, one folder will contain the implementation of the game’s logic where another may be an implementation of the GUI. The GUI will be dependent on the games folder, just like with the submodule approach, and there will have to be a weird import set up to go to the root directory and grab the requirements. However, everything will always be in sync and thorough unit testing will make it clear when something has broken.\nNeither of the two approaches are necessarily better than the other, but I ultimately went with the monolithic approach. The inconvenience of getting imports to work seemed minor to the headaches that would ensue with the submodules approach.\nNext Time Next time, we’ll be starting off with setting up our github repository with our monolithic structure in mind. Once that is complete, we can get the basics of the game working by defining a format for a board that can be read from text files. Lastly, we’ll look into a structure for AI in games and how it will affect our design and implementation.\n","permalink":"http://localhost:1313/posts/making-rush-hour-1/","summary":"\u003cp\u003eThis is the first in a series of posts where I discuss implementing a version of \u003ca href=\"https://apps.apple.com/us/app/unblock-me/id315019111\"\u003eUnblock Me\u003c/a\u003e and \u003ca href=\"https://en.wikipedia.org/wiki/Rush_Hour_(puzzle)\"\u003eRush Hour\u003c/a\u003e; sample screen shots can be seen in figure one. For the implementation, I’ve decided to use Python 2.7, however, you should be able to follow along with any language. My hope is that each of these posts will be more than just a copy and paste tutorial. To facilitate this, I will be taking deep dives into design decisions, test-driven design, common game AI architecture, general software structure, requirements gathering, servers, and more.\u003c/p\u003e","title":"Making Rush Hour: Requirements and Basic Structuring"},{"content":"Generative Design in Minecraft (GDMC) GDMC is a competition to generate settlements within a selection of a minecraft map. The project\u0026rsquo;s website provides details on how the competition works and what is expected. However, the main point to get across right now is that they are judging based on adaptability, functionality, narrative, and aesthetics. Adaptability is about the generation technique working with the map rather than ignoring it. An example of ignoring the environment would be generating a wooden village where there are no trees. The functionality component is based on real world criteria such as access to food, defenses, etc. The narrative component is about how every area has a story to tell. An example is a castle with part of the tower knocked down. Lastly, aesthetics is about how it looks both in terms of believability and general appeal.\nMCEdit To generate settlements, the competition has gone the route of using MCEdit to allow competitors to view, generate, and modify minecraft maps. GDMC provides a wiki with easy to use instructions for installing and general set up. The wiki also provides an example cellular automata script for generating structures seen in figure one. As you can see, the output isn’t great, but it provides a nice starting point. It, also, shows how to work with the MCEdit filters which is how we can interact with the maps.\nFigure 1: Example cellular automata output from CASG_Example.py Filters A filter is how we are able to modify maps. To activate a filter, a user makes a selection on the map via a left click and dragging your mouse. From there, on the bottom of the screen, there is a potion looking icon that when pressed will open the filter menu. This provides a drop down menu of available filters. Each of these filters provides a set of options and the ability to perform their respective actions. When activated they will make modifications to the map given the users selection area. Each of the filters are Python 2.7 scripts located in the stock-filters directory.\nFilter Basics The wiki provides some helpful commentary in getting started with filters, but the script is a bit too complicated for a starting point. There are, however, two things that every filter has in common: the perform function and inputs tuple.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Replace Eight Corners\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def perform(level, box, options): pass When a filter is activated, the engine will call the perform function and pass the level data (this data structure will be explored further in the next post), the bounding box, and the set of options a user has defined. The bounding box defines the origin of the box the user created and the size. The options is a dictionary based on the inputs defined in the above script. Therefore, to access the materials you could use options[“Material”] to be able to see what the user set.\nBox in all Eight Corners of Selection Now that we understand the basics, we can start with a simple filter. The goal of this filter is to place a user defined material in all eight corners of the user’s selection. The end result can be seen in figure two. The first step here is to define the inputs for the user. In this case, the above inputs code is exactly what we need.\nFigure 2: Example of placing blocks at all eight corners of user\u0026#39;s selection space Now we need to know how to draw a block and this can be found in the utility functions provided by NYU. I haven’t figured out the point of the function setBlockDataAt yet, but in the second post I intend to investigate more to figure it out. In the meantime, I wrote a simpler function because the data was always set to 0 in the examples I could find.\ndef draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) With that complete, the only problem now is figuring out how to use the bounding box to find the eight corners. As noted above, the way the bounding box works is by providing an origin and size vector. All variations of adding these two together will provide eight values which are, coincidentally, the corners of the cube. The full filter can be seen below.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Replace Eight Corners\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) def perform(level, box, options): material = options[\u0026#34;Material\u0026#34;] draw_block(level, box.origin.x, box.origin.y, box.origin.z, material) draw_block(level, box.origin.x + box.size.x, box.origin.y, box.origin.z, material) draw_block(level, box.origin.x, box.origin.y + box.size.y, box.origin.z, material) draw_block(level, box.origin.x, box.origin.y, box.origin.z + box.size.z, material) draw_block(level, box.origin.x + box.size.x, box.origin.y + box.size.y, box.origin.z, material) draw_block(level, box.origin.x + box.size.x, box.origin.y, box.origin.z + box.size.z, material) draw_block(level, box.origin.x, box.origin.y + box.size.y, box.origin.z + box.size.z, material) draw_block(level, box.origin.x + box.size.x, box.origin.y + box.size.y, box.origin.z + box.size.z, material) Fill Selection In comparison to the eight boxes, this is a lot easier conceptually. All we want to do is fill the entire users selection with a material. The end result can be seen in figure three.\nFigure 3: Two examples of filling in users selection with a different materials The setup is exactly the same as last time where you can use the inputs to define the material. We can even use the draw_block function. At this point, it is probably best to create a script that contains common functions that could be useful in the future. From there, we need to create a function fill_box which takes in the level, origin, size, and material. To fill the box, it is as simple as three for loops that go through all possible x, y, and z values. It is important that you loop from the minimum to the maximum of these, else there is a chance you will not completely fill in the box.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from mcplatform import * inputs = ( (\u0026#34;Replace All\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) def fill_box(level, origin, size, material): final_x = origin.x + size.x final_y = origin.y + size.y final_z = origin.z + size.z for x in range(min(origin.x, final_x), max(origin.x, final_x)): for y in range(min(origin.y, final_y), max(origin.y, final_y)): for z in range(min(origin.z, final_z), max(origin.z, final_z)): draw_block(level, x, y, z, material) def perform(level, box, options): fill_box(level, box.origin, box.size, options[\u0026#34;Material\u0026#34;]) Box Outline In this case we want to take the user’s selection and draw blocks along the edges, an example can be seen in figure four. The complexity for this problem is creating a function that will properly draw lines. Specifically, it is necessary to make sure it can draw diagonal lines for the sake of completeness.\nFigure 4: Example of drawing the edges for a user\u0026#39;s selection The main difficulty in this problem is making sure every direction a line can move is accounted for. The list is quite long but mainly requires some attentiveness on our our part when defining all the possibilities.\ndirections = [ (1,0,0),(-1,0,0),(0,1,0),(0,-1,0),(0,0,1),(0,0,-1),\\ (1,1,0),(-1,1,0),(1,-1,0),(-1,-1,0),(0,1,1),(0,-1,1),\\ (0,1,-1),(0,-1,-1),(1,0,1),(-1,0,1),(1,0,-1),(-1,0,-1),\\ (1,1,1),(-1,1,1),(1,-1,1),(1,1,-1),(-1,-1,1),(-1,1,-1),\\ (1,-1,-1),(-1,-1,-1) ] We now have the task of using the directions array to draw the line along the shortest path from the starting point to the end point. I first wrote this with a recursive method, where it would find the point closest, with the manhattan distance, and then draw a block. It would recursively call itself again, drawing a block at the next closest point, until it had reached the end point. Please note that I did not put in object avoidance into this method as it was beyond the scope of the problem. With the recursive method complete, it became clear a while loop would be just as clear with minimal code changes and be more performant since tail recursion is not supported by Python.\nOnce drawing a line was completed, the last step was to use the vertices I defined in the section dedicated to drawing materials in all eight corners to draw the edges as well. The code for the filter is below.\nfrom pymclevel import alphaMaterials, MCSchematic, MCLevel, BoundingBox from pymclevel.box import Vector from mcplatform import * inputs = ( (\u0026#34;Replace All\u0026#34;, \u0026#34;label\u0026#34;), (\u0026#34;Material\u0026#34;, alphaMaterials.CoalBlock), (\u0026#34;Creator: Colan Biemer\u0026#34;, \u0026#34;label\u0026#34;) ) def vector_equals(v1, v2): return v1.x == v2.x and v1.y == v2.y and v1.z == v2.z def manhattan_distance(start, end): return abs(end.x - start.x) + abs(end.y - start.y) + abs(end.z - start.z) def draw_block(level, x, y, z, material): level.setBlockAt(x, y, z, material.ID) level.setBlockDataAt(x, y, z, 0) def draw_block(level, point, material): level.setBlockAt(point.x, point.y, point.z, material.ID) level.setBlockDataAt(point.x, point.y, point.z, 0) def fill_box(level, origin, size, material): final_x = origin.x + size.x final_y = origin.y + size.y final_z = origin.z + size.z for x in range(min(origin.x, final_x), max(origin.x, final_x)): for y in range(min(origin.y, final_y), max(origin.y, final_y)): for z in range(min(origin.z, final_z), max(origin.z, final_z)): draw_block(level, x, y, z, material) def draw_line(level, start, end, material): directions = [(1,0,0),(-1,0,0),(0,1,0),(0,-1,0),(0,0,1),(0,0,-1),\\ (1,1,0),(-1,1,0),(1,-1,0),(-1,-1,0),(0,1,1),(0,-1,1),\\ (0,1,-1),(0,-1,-1),(1,0,1),(-1,0,1),(1,0,-1),(-1,0,-1),\\ (1,1,1),(-1,1,1),(1,-1,1),(1,1,-1),(-1,-1,1),(-1,1,-1),\\ (1,-1,-1),(-1,-1,-1)] draw_block(level, start, material) while not vector_equals(start, end): new_s = start + directions[0] dist = manhattan_distance(start, end) for i in range(1, len(directions)): s = start + directions[i] d = manhattan_distance(s, end) if d \u0026lt; dist: new_s = s dist = d start = new_s draw_block(level, start, material) def draw_box_outline(level, box, material): point_1 = box.origin point_2 = Vector(box.origin.x + box.size.x, box.origin.y, box.origin.z) point_3 = Vector(box.origin.x, box.origin.y + box.size.y, box.origin.z) point_4 = Vector(box.origin.x, box.origin.y, box.origin.z + box.size.z) point_5 = Vector(box.origin.x + box.size.x, box.origin.y + box.size.y, box.origin.z) point_6 = Vector(box.origin.x + box.size.x, box.origin.y, box.origin.z + box.size.z) point_7 = Vector(box.origin.x, box.origin.y + box.size.y, box.origin.z + box.size.z,) point_8 = Vector(box.origin.x + box.size.x, box.origin.y + box.size.y, box.origin.z + box.size.z) draw_line(level, point_1, point_2, material) draw_line(level, point_1, point_3, material) draw_line(level, point_1, point_4, material) draw_line(level, point_2, point_6, material) draw_line(level, point_4, point_6, material) draw_line(level, point_3, point_7, material) draw_line(level, point_4, point_7, material) draw_line(level, point_7, point_8, material) draw_line(level, point_6, point_8, material) draw_line(level, point_8, point_5, material) draw_line(level, point_5, point_2, material) draw_line(level, point_5, point_3, material) def perform(level, box, options): draw_box_outline(level, box, options[\u0026#34;Material\u0026#34;]) ","permalink":"http://localhost:1313/posts/gdmc1/","summary":"\u003ch1 id=\"generative-design-in-minecraft-gdmc\"\u003eGenerative Design in Minecraft (GDMC)\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"http://gendesignmc.engineering.nyu.edu/\"\u003eGDMC\u003c/a\u003e is a competition to generate settlements within a selection of a minecraft map. The \u003ca href=\"http://gendesignmc.engineering.nyu.edu/\"\u003eproject\u0026rsquo;s website\u003c/a\u003e provides details on how the competition works and what is expected. However, the main point to get across right now is that they are judging based on adaptability, functionality, narrative, and aesthetics. Adaptability is about the generation technique working with the map rather than ignoring it. An example of ignoring the environment would be generating a wooden village where there are no trees. The functionality component is based on real world criteria such as access to food, defenses, etc. The narrative component is about how every area has a story to tell. An example is a castle with part of the tower knocked down. Lastly, aesthetics is about how it looks both in terms of believability and general appeal.\u003c/p\u003e","title":"Generative Design in Mineraft: MCEdit Basics"},{"content":"This is a quick walk through of how to take c++ and run it with Python through bindings. If you find yourself wishing to learn more on the topic, Swig’s website for working with Python is a good start. My experience in setting this up was far more tedious than it had to be and I hope this will save people some time. As a note, I currently work on Ubuntu 16.04 and Python 2.7; this will be tailored to those dependencies, however, I do not believe any major changes will be required to the setup.py file based on Swig\u0026rsquo;s website and a StackOverflow question for Python 3. In addition, the majority of operating systems should be covered by this walk through, with minor tweaks such as yum instead of apt-get for select operating systems.\n1. Install # python-dev sudo apt-get install python-dev # python2.x sudo apt-get install python3-dev # python3.x # swig sudo apt-get install swig 2. Source c++ Fibonacci implementation, filename: fib.cpp\n#include \u0026#34;fib.h\u0026#34; int fibonacci(int n) { if(n \u0026lt;= 1) return n; return fibonacci(n-1) + fibonacci(n-2); } c++ fibonacci header file, filename: fib.h. I\u0026rsquo;m going to explain why this file exists in a moment.\nint fibonacci(int n); The next file is the interface file for swig, fib.i. This is telling swig what bindings it will need to create and is why we implemented fib.h.\n%module Fibonacci %{ #include \u0026#34;fib.h\u0026#34; %} %include \u0026#34;fib.h\u0026#34; The alternative to creating the fib.h file is directly below. For this we define each function individually for swig to then bind.\n%module Fibonacci %{ int fibonacci(int n); %} int fibonacci(int n); 3. Build setup.py, this file is taken directly from Swig\u0026rsquo;s documentation and modified slightly.\n#!/usr/bin/env python from distutils.core import setup, Extension fib_module = Extension( \u0026#39;_Fibonacci\u0026#39;, sources=[\u0026#39;fib_wrap.cxx\u0026#39;, \u0026#39;fib.cpp\u0026#39;], # fib_wrap.cxx is going to be generated by swig ) setup ( name = \u0026#39;Fibonacci\u0026#39;, version = \u0026#39;0.0\u0026#39;, author = \u0026#34;YOUR_NAME\u0026#34;, description = \u0026#34;Fibonacci swig\u0026#34;, ext_modules = [fib_module], py_modules = [\u0026#34;Fibonacci\u0026#34;], # name of module that we\u0026#39;re going import ) build.sh or whatever you fancy.\n#!/bin/bash swig -c++ -python fib.i python setup.py build_ext --inplace 4. Run Assign permissions (e.g. chmod 755 build.sh) and run ./build.sh. From there you can go into the python console and test by running the following:\n$ python \u0026gt;\u0026gt;\u0026gt; import Fibonacci \u0026gt;\u0026gt;\u0026gt; Fibonacci.fibonacci(10) 55 5. Conclusion Please let me know if anything here can be improved so I can update this for future readers. Regardless, I hope this helped some of you with your projects/work and saved you some time.\n","permalink":"http://localhost:1313/posts/first/","summary":"\u003cp\u003eThis is a quick walk through of how to take c++ and run it with Python through bindings. If you find yourself wishing to learn more on the topic, \u003ca href=\"http://www.swig.org/Doc1.3/Python.html\"\u003eSwig’s website\u003c/a\u003e for working with Python is a good start. My experience in setting this up was far more tedious than it had to be and I hope this will save people some time. As a note, I currently work on Ubuntu 16.04 and Python 2.7; this will be tailored to those dependencies, however, I do not believe any major changes will be required to the setup.py file based on \u003ca href=\"http://www.swig.org/Doc1.3/Python.html\"\u003eSwig\u0026rsquo;s website\u003c/a\u003e and a \u003ca href=\"https://stackoverflow.com/questions/32667888/building-extension-for-python-3-with-swig-and-distutils\"\u003eStackOverflow question for Python 3\u003c/a\u003e. In addition, the majority of operating systems should be covered by this walk through, with minor tweaks such as yum instead of apt-get for select operating systems.\u003c/p\u003e","title":"C++ to Python Bindings with Swig"},{"content":"Biemer, C., \u0026amp; Cooper, S. (2024, May). Solution Path Heuristics for Predicting Difficulty and Enjoyment Ratings of Roguelike Level Segments. In Proceedings of the 19th International Conference on the Foundations of Digital Games (pp. 1-8). Paper\nBiemer, C. F. (2023, October). Dynamic difficulty adjustment via procedural level generation guided by a Markov decision process for platformers and roguelikes. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (Vol. 19, No. 1, pp. 436-439). Paper\nBiemer, C., \u0026amp; Cooper, S. (2022, October). Level Assembly as a Markov Decision Process. In 2022 Proceedings of the Experimental AI in Games Workshop. Paper, Talk, Code\nBiemer, C., \u0026amp; Cooper, S. (2022, August). On Linking Level Segments. In 2022 IEEE Conference on Games (CoG) (pp. 199-205). ★ Best Paper Nominee Paper, Talk, Code\nBiemer, C., Hervella, A., \u0026amp; Cooper, S. (2021, August). Gram-Elites: N-Gram Based Quality-Diversity Search. In The 16th International Conference on the Foundations of Digital Games (FDG) 2021 (pp. 1-6). Paper, Talk, Code\nVillareale, J., Biemer, C., Seif El-Nasr, M., \u0026amp; Zhu, J. (2020, September). Reflection in Game-Based Learning: A Survey of Programming Games. In International Conference on the Foundations of Digital Games (pp. 1-9). Paper\n","permalink":"http://localhost:1313/publications/","summary":"\u003cp\u003eBiemer, C., \u0026amp; Cooper, S. (2024, May). Solution Path Heuristics for Predicting Difficulty and Enjoyment Ratings of Roguelike Level Segments. In Proceedings of the 19th International Conference on the Foundations of Digital Games (pp. 1-8). \u003cbr\u003e\n\u003ca href=\"/pdf/2024_solution_path_heuristics.pdf\"\u003ePaper\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eBiemer, C. F. (2023, October). Dynamic difficulty adjustment via procedural level generation guided by a Markov decision process for platformers and roguelikes. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (Vol. 19, No. 1, pp. 436-439). \u003cbr\u003e\n\u003ca href=\"/pdf/2023_ddaviaplgviamdp.pdf\"\u003ePaper\u003c/a\u003e\u003c/p\u003e","title":"Publications"}]